{"version":3,"file":"","sourceRoot":"","sources":["../node_modules/ray-aabb/ray-aabb.js","../node_modules/ray-direction-classify/ray-direction-classify.js","../node_modules/synaptic/dist/synaptic.js","main.js"],"sourcesContent":["var classify = require('ray-direction-classify');\n\nmodule.exports = createRay;\n\nvar tests = {};\nvar max = Math.max;\nvar abs = Math.abs;\n\ntests[classify.MMM] = function testMMM(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[0] < lb[0] ||\n          ro[1] < lb[1] ||\n          ro[2] < lb[2] ||\n          ray.jbyi * lb[0] - ub[1] + ray.cxy > 0 ||\n          ray.ibyj * lb[1] - ub[0] + ray.cyx > 0 ||\n          ray.jbyk * lb[2] - ub[1] + ray.czy > 0 ||\n          ray.kbyj * lb[1] - ub[2] + ray.cyz > 0 ||\n          ray.kbyi * lb[0] - ub[2] + ray.cxz > 0 ||\n          ray.ibyk * lb[2] - ub[0] + ray.czx > 0);\n};\ntests[classify.MMP] = function testMMP(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[0] < lb[0] ||\n          ro[1] < lb[1] ||\n          ro[2] > ub[2] ||\n          ray.jbyi * lb[0] - ub[1] + ray.cxy > 0 ||\n          ray.ibyj * lb[1] - ub[0] + ray.cyx > 0 ||\n          ray.jbyk * ub[2] - ub[1] + ray.czy > 0 ||\n          ray.kbyj * lb[1] - lb[2] + ray.cyz < 0 ||\n          ray.kbyi * lb[0] - lb[2] + ray.cxz < 0 ||\n          ray.ibyk * ub[2] - ub[0] + ray.czx > 0);\n};\ntests[classify.MPM] = function testMPM(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[0] < lb[0] ||\n          ro[1] > ub[1] ||\n          ro[2] < lb[2] ||\n          ray.jbyi * lb[0] - lb[1] + ray.cxy < 0 ||\n          ray.ibyj * ub[1] - ub[0] + ray.cyx > 0 ||\n          ray.jbyk * lb[2] - lb[1] + ray.czy < 0 ||\n          ray.kbyj * ub[1] - ub[2] + ray.cyz > 0 ||\n          ray.kbyi * lb[0] - ub[2] + ray.cxz > 0 ||\n          ray.ibyk * lb[2] - ub[0] + ray.czx > 0);\n};\ntests[classify.MPP] = function testMPP(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[0] < lb[0] ||\n          ro[1] > ub[1] ||\n          ro[2] > ub[2] ||\n          ray.jbyi * lb[0] - lb[1] + ray.cxy < 0 ||\n          ray.ibyj * ub[1] - ub[0] + ray.cyx > 0 ||\n          ray.jbyk * ub[2] - lb[1] + ray.czy < 0 ||\n          ray.kbyj * ub[1] - lb[2] + ray.cyz < 0 ||\n          ray.kbyi * lb[0] - lb[2] + ray.cxz < 0 ||\n          ray.ibyk * ub[2] - ub[0] + ray.czx > 0);\n};\ntests[classify.PMM] = function testPMM(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[0] > ub[0] ||\n          ro[1] < lb[1] ||\n          ro[2] < lb[2] ||\n          ray.jbyi * ub[0] - ub[1] + ray.cxy > 0 ||\n          ray.ibyj * lb[1] - lb[0] + ray.cyx < 0 ||\n          ray.jbyk * lb[2] - ub[1] + ray.czy > 0 ||\n          ray.kbyj * lb[1] - ub[2] + ray.cyz > 0 ||\n          ray.kbyi * ub[0] - ub[2] + ray.cxz > 0 ||\n          ray.ibyk * lb[2] - lb[0] + ray.czx < 0);\n};\ntests[classify.PMP] = function testPMP(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[0] > ub[0] ||\n          ro[1] < lb[1] ||\n          ro[2] > ub[2] ||\n          ray.jbyi * ub[0] - ub[1] + ray.cxy > 0 ||\n          ray.ibyj * lb[1] - lb[0] + ray.cyx < 0 ||\n          ray.jbyk * ub[2] - ub[1] + ray.czy > 0 ||\n          ray.kbyj * lb[1] - lb[2] + ray.cyz < 0 ||\n          ray.kbyi * ub[0] - lb[2] + ray.cxz < 0 ||\n          ray.ibyk * ub[2] - lb[0] + ray.czx < 0);\n};\ntests[classify.PPM] = function testPPM(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[0] > ub[0] ||\n          ro[1] > ub[1] ||\n          ro[2] < lb[2] ||\n          ray.jbyi * ub[0] - lb[1] + ray.cxy < 0 ||\n          ray.ibyj * ub[1] - lb[0] + ray.cyx < 0 ||\n          ray.jbyk * lb[2] - lb[1] + ray.czy < 0 ||\n          ray.kbyj * ub[1] - ub[2] + ray.cyz > 0 ||\n          ray.kbyi * ub[0] - ub[2] + ray.cxz > 0 ||\n          ray.ibyk * lb[2] - lb[0] + ray.czx < 0);\n};\ntests[classify.PPP] = function testPPP(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[0] > ub[0] ||\n          ro[1] > ub[1] ||\n          ro[2] > ub[2] ||\n          ray.jbyi * ub[0] - lb[1] + ray.cxy < 0 ||\n          ray.ibyj * ub[1] - lb[0] + ray.cyx < 0 ||\n          ray.jbyk * ub[2] - lb[1] + ray.czy < 0 ||\n          ray.kbyj * ub[1] - lb[2] + ray.cyz < 0 ||\n          ray.kbyi * ub[0] - lb[2] + ray.cxz < 0 ||\n          ray.ibyk * ub[2] - lb[0] + ray.czx < 0);\n};\ntests[classify.POO] = function testPOO(ray, lb, ub) {\n  var ro = ray.ro;\n  var ro1 = ro[1];\n  var ro2 = ro[2];\n\n  return !(ro[0] > ub[0] ||\n          ro1 < lb[1] ||\n          ro1 > ub[1] ||\n          ro2 < lb[2] ||\n          ro2 > ub[2]);\n};\ntests[classify.MOO] = function testMOO(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[0] < lb[0] ||\n          ro[1] < lb[1] ||\n          ro[1] > ub[1] ||\n          ro[2] < lb[2] ||\n          ro[2] > ub[2]);\n};\ntests[classify.OPO] = function testOPO(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[1] > ub[1] ||\n          ro[0] < lb[0] ||\n          ro[0] > ub[0] ||\n          ro[2] < lb[2] ||\n          ro[2] > ub[2]);\n};\ntests[classify.OMO] = function testOMO(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[1] < lb[1] ||\n          ro[0] < lb[0] ||\n          ro[0] > ub[0] ||\n          ro[2] < lb[2] ||\n          ro[2] > ub[2]);\n};\ntests[classify.OOP] = function testOOP(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[2] > ub[2] ||\n          ro[0] < lb[0] ||\n          ro[0] > ub[0] ||\n          ro[1] < lb[1] ||\n          ro[1] > ub[1]);\n};\ntests[classify.OOM] = function testOOM(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[2] < lb[2] ||\n          ro[0] < lb[0] ||\n          ro[0] > ub[0] ||\n          ro[1] < lb[1] ||\n          ro[1] > ub[1]);\n};\ntests[classify.OMM] = function testOMM(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[0] < lb[0] ||\n          ro[0] > ub[0] ||\n          ro[1] < lb[1] ||\n          ro[2] < lb[2] ||\n          ray.jbyk * lb[2] - ub[1] + ray.czy > 0 ||\n          ray.kbyj * lb[1] - ub[2] + ray.cyz > 0);\n};\ntests[classify.OMP] = function testOMP(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[0] < lb[0] ||\n          ro[0] > ub[0] ||\n          ro[1] < lb[1] ||\n          ro[2] > ub[2] ||\n          ray.jbyk * ub[2] - ub[1] + ray.czy > 0 ||\n          ray.kbyj * lb[1] - lb[2] + ray.cyz < 0);\n};\ntests[classify.OPM] = function testOPM(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[0] < lb[0] ||\n          ro[0] > ub[0] ||\n          ro[1] > ub[1] ||\n          ro[2] < lb[2] ||\n          ray.jbyk * lb[2] - lb[1] + ray.czy < 0 ||\n          ray.kbyj * ub[1] - ub[2] + ray.cyz > 0);\n};\ntests[classify.OPP] = function testOPP(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[0] < lb[0] ||\n          ro[0] > ub[0] ||\n          ro[1] > ub[1] ||\n          ro[2] > ub[2] ||\n          ray.jbyk * ub[2] - lb[1] + ray.czy < 0 ||\n          ray.kbyj * ub[1] - lb[2] + ray.cyz < 0);\n};\ntests[classify.MOM] = function testMOM(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[1] < lb[1] ||\n          ro[1] > ub[1] ||\n          ro[0] < lb[0] ||\n          ro[2] < lb[2] ||\n          ray.kbyi * lb[0] - ub[2] + ray.cxz > 0 ||\n          ray.ibyk * lb[2] - ub[0] + ray.czx > 0);\n};\ntests[classify.MOP] = function testMOP(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[1] < lb[1] ||\n          ro[1] > ub[1] ||\n          ro[0] < lb[0] ||\n          ro[2] > ub[2] ||\n          ray.kbyi * lb[0] - lb[2] + ray.cxz < 0 ||\n          ray.ibyk * ub[2] - ub[0] + ray.czx > 0);\n};\ntests[classify.POM] = function testPOM(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[1] < lb[1] ||\n          ro[1] > ub[1] ||\n          ro[0] > ub[0] ||\n          ro[2] < lb[2] ||\n          ray.kbyi * ub[0] - ub[2] + ray.cxz > 0 ||\n          ray.ibyk * lb[2] - lb[0] + ray.czx < 0);\n};\ntests[classify.POP] = function testPOP(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[1] < lb[1] ||\n          ro[1] > ub[1] ||\n          ro[0] > ub[0] ||\n          ro[2] > ub[2] ||\n          ray.kbyi * ub[0] - lb[2] + ray.cxz < 0 ||\n          ray.ibyk * ub[2] - lb[0] + ray.czx < 0);\n};\ntests[classify.MMO] = function testMMO(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[2] < lb[2] ||\n          ro[2] > ub[2] ||\n          ro[0] < lb[0] ||\n          ro[1] < lb[1] ||\n          ray.jbyi * lb[0] - ub[1] + ray.cxy > 0 ||\n          ray.ibyj * lb[1] - ub[0] + ray.cyx > 0);\n};\ntests[classify.MPO] = function testMPO(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[2] < lb[2] ||\n          ro[2] > ub[2] ||\n          ro[0] < lb[0] ||\n          ro[1] > ub[1] ||\n          ray.jbyi * lb[0] - lb[1] + ray.cxy < 0 ||\n          ray.ibyj * ub[1] - ub[0] + ray.cyx > 0);\n};\ntests[classify.PMO] = function testPMO(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[2] < lb[2] ||\n          ro[2] > ub[2] ||\n          ro[0] > ub[0] ||\n          ro[1] < lb[1] ||\n          ray.jbyi * ub[0] - ub[1] + ray.cxy > 0 ||\n          ray.ibyj * lb[1] - lb[0] + ray.cyx < 0);\n};\ntests[classify.PPO] = function testPPO(ray, lb, ub) {\n  var ro = ray.ro;\n\n  return !(ro[2] < lb[2] ||\n          ro[2] > ub[2] ||\n          ro[0] > ub[0] ||\n          ro[1] > ub[1] ||\n          ray.jbyi * ub[0] - lb[1] + ray.cxy < 0 ||\n          ray.ibyj * ub[1] - lb[0] + ray.cyx < 0);\n};\n\nvar lerps = {};\n\nlerps[classify.MMM] = function lerpMMM(ray, aabb, norm) {\n  var ro = ray.ro;\n  var ub = aabb[1];\n  var a = (ub[0] - ro[0]) * ray.ii;\n  var b = (ub[1] - ro[1]) * ray.ij;\n  var c = (ub[2] - ro[2]) * ray.ik;\n\n  norm[0] = (a >= b && a >= c) ? 1 : 0;\n  norm[1] = (b >= c && b >= a) ? 1 : 0;\n  norm[2] = (c >= a && c >= b) ? 1 : 0;\n\n  return max(a, b, c);\n};\n\nlerps[classify.MMP] = function lerpMMP(ray, aabb, norm) {\n  var ro = ray.ro;\n  var ub = aabb[1];\n  var lb = aabb[0];\n\n  var a = (ub[0] - ro[0]) * ray.ii;\n  var b = (ub[1] - ro[1]) * ray.ij;\n  var c = (lb[2] - ro[2]) * ray.ik;\n\n  norm[0] = (a >= b && a >= c) ?  1 : 0;\n  norm[1] = (b >= c && b >= a) ?  1 : 0;\n  norm[2] = (c >= a && c >= b) ? -1 : 0;\n\n  return max(a, b, c);\n};\n\nlerps[classify.MPM] = function lerpMPM(ray, aabb, norm) {\n  var ro = ray.ro;\n  var ub = aabb[1];\n  var lb = aabb[0];\n\n  var a = (ub[0] - ro[0]) * ray.ii;\n  var b = (lb[1] - ro[1]) * ray.ij;\n  var c = (ub[2] - ro[2]) * ray.ik;\n\n  norm[0] = (a >= b && a >= c) ?  1 : 0;\n  norm[1] = (b >= c && b >= a) ? -1 : 0;\n  norm[2] = (c >= a && c >= b) ?  1 : 0;\n\n  return max(a, b, c);\n};\n\nlerps[classify.MPP] = function lerpMPP(ray, aabb, norm) {\n  var ro = ray.ro;\n  var ub = aabb[1];\n  var lb = aabb[0];\n\n  var a = (ub[0] - ro[0]) * ray.ii;\n  var b = (lb[1] - ro[1]) * ray.ij;\n  var c = (lb[2] - ro[2]) * ray.ik;\n\n  norm[0] = (a >= b && a >= c) ?  1 : 0;\n  norm[1] = (b >= c && b >= a) ? -1 : 0;\n  norm[2] = (c >= a && c >= b) ? -1 : 0;\n\n  return max(a, b, c);\n};\n\nlerps[classify.PMM] = function lerpPMM(ray, aabb, norm) {\n  var ro = ray.ro;\n  var ub = aabb[1];\n  var lb = aabb[0];\n\n  var a = (lb[0] - ro[0]) * ray.ii;\n  var b = (ub[1] - ro[1]) * ray.ij;\n  var c = (ub[2] - ro[2]) * ray.ik;\n\n  norm[0] = (a >= b && a >= c) ? -1 : 0;\n  norm[1] = (b >= c && b >= a) ?  1 : 0;\n  norm[2] = (c >= a && c >= b) ?  1 : 0;\n\n  return max(a, b, c);\n};\n\nlerps[classify.PMP] = function lerpPMP(ray, aabb, norm) {\n  var ro = ray.ro;\n  var ub = aabb[1];\n  var lb = aabb[0];\n\n  var a = (lb[0] - ro[0]) * ray.ii;\n  var b = (ub[1] - ro[1]) * ray.ij;\n  var c = (lb[2] - ro[2]) * ray.ik;\n\n  norm[0] = (a >= b && a >= c) ? -1 : 0;\n  norm[1] = (b >= c && b >= a) ?  1 : 0;\n  norm[2] = (c >= a && c >= b) ? -1 : 0;\n\n  return max(a, b, c);\n};\n\nlerps[classify.PPM] = function lerpPPM(ray, aabb, norm) {\n  var ro = ray.ro;\n  var lb = aabb[0];\n  var ub = aabb[1];\n\n  var a = (lb[0] - ro[0]) * ray.ii;\n  var b = (lb[1] - ro[1]) * ray.ij;\n  var c = (ub[2] - ro[2]) * ray.ik;\n\n  norm[0] = (a >= b && a >= c) ? -1 : 0;\n  norm[1] = (b >= c && b >= a) ? -1 : 0;\n  norm[2] = (c >= a && c >= b) ?  1 : 0;\n\n  return max(a, b, c);\n};\n\nlerps[classify.PPP] = function lerpPPP(ray, aabb, norm) {\n  var ro = ray.ro;\n  var lb = aabb[0];\n\n  var a = (lb[0] - ro[0]) * ray.ii;\n  var b = (lb[1] - ro[1]) * ray.ij;\n  var c = (lb[2] - ro[2]) * ray.ik;\n\n  norm[0] = (a >= b && a >= c) ? -1 : 0;\n  norm[1] = (b >= c && b >= a) ? -1 : 0;\n  norm[2] = (c >= a && c >= b) ? -1 : 0;\n\n  return max(a, b, c);\n};\n\nlerps[classify.OMM] = function lerpOMM(ray, aabb, norm) {\n  var ro = ray.ro;\n  var ub = aabb[1];\n\n  var a = (ub[1] - ro[1]) * ray.ij;\n  var b = (ub[2] - ro[2]) * ray.ik;\n\n  norm[0] = 0\n  norm[1] = (a >= b) ? 1 : 0;\n  norm[2] = (b >= a) ? 1 : 0;\n\n  return max(a, b);\n};\n\nlerps[classify.OMP] = function lerpOMP(ray, aabb, norm) {\n  var ro = ray.ro;\n\n  var a = (aabb[1][1] - ro[1]) * ray.ij;\n  var b = (aabb[0][2] - ro[2]) * ray.ik;\n\n  norm[0] = 0\n  norm[1] = (a >= b) ?  1 : 0;\n  norm[2] = (b >= a) ? -1 : 0;\n\n  return max(a, b);\n};\n\nlerps[classify.OPM] = function lerpOPM(ray, aabb, norm) {\n  var ro = ray.ro;\n\n  var a = (aabb[0][1] - ro[1]) * ray.ij;\n  var b = (aabb[1][2] - ro[2]) * ray.ik;\n\n  norm[0] = 0\n  norm[1] = (a >= b) ? -1 : 0;\n  norm[2] = (b >= a) ?  1 : 0;\n\n  return max(a, b);\n};\n\nlerps[classify.OPP] = function lerpOPP(ray, aabb, norm) {\n  var ro = ray.ro;\n  var lb = aabb[0];\n\n  var a = (lb[1] - ro[1]) * ray.ij;\n  var b = (lb[2] - ro[2]) * ray.ik;\n\n  norm[0] = 0\n  norm[1] = (a >= b) ? -1 : 0;\n  norm[2] = (b >= a) ? -1 : 0;\n\n  return max(a, b);\n}\n\nlerps[classify.MOM] = function lerpMOM(ray, aabb, norm) {\n  var ro = ray.ro;\n  var ub = aabb[1];\n\n  var a = (ub[0] - ro[0]) * ray.ii;\n  var b = (ub[2] - ro[2]) * ray.ik;\n\n  norm[0] = (a >= b) ? 1 : 0;\n  norm[1] = 0\n  norm[2] = (b >= a) ? 1 : 0;\n\n  return max(a, b);\n};\n\nlerps[classify.MOP] = function lerpMOP(ray, aabb, norm) {\n  var ro = ray.ro;\n\n  var a = (aabb[1][0] - ro[0]) * ray.ii;\n  var b = (aabb[0][2] - ro[2]) * ray.ik;\n\n  norm[0] = (a >= b) ?  1 : 0;\n  norm[1] = 0\n  norm[2] = (b >= a) ? -1 : 0;\n\n  return max(a, b);\n};\n\nlerps[classify.POM] = function lerpPOM(ray, aabb, norm) {\n  var ro = ray.ro;\n\n  var a = (aabb[0][0] - ray.ro[0]) * ray.ii;\n  var b = (aabb[1][2] - ray.ro[2]) * ray.ik;\n\n  norm[0] = (a >= b) ? -1 : 0;\n  norm[1] = 0;\n  norm[2] = (b >= a) ?  1 : 0;\n\n  return max(a, b);\n};\n\nlerps[classify.POP] = function lerpPOP(ray, aabb, norm) {\n  var ro = ray.ro;\n  var lb = aabb[0];\n\n  var a = (lb[0] - ro[0]) * ray.ii;\n  var b = (lb[2] - ro[2]) * ray.ik;\n\n  norm[0] = (a >= b) ? -1 : 0;\n  norm[1] = 0\n  norm[2] = (b >= a) ? -1 : 0;\n\n  return max(a, b);\n}\n\nlerps[classify.MMO] = function lerpMMO(ray, aabb, norm) {\n  var ro = ray.ro;\n  var ub = aabb[1];\n\n  var a = (ub[0] - ro[0]) * ray.ii;\n  var b = (ub[1] - ro[1]) * ray.ij;\n\n  norm[0] = (a >= b) ? 1 : 0;\n  norm[1] = (b >= a) ? 1 : 0;\n  norm[2] = 0\n\n  return max(a, b);\n}\n\nlerps[classify.MPO] = function lerpMPO(ray, aabb, norm) {\n  var ro = ray.ro;\n\n  var a = (aabb[1][0] - ro[0]) * ray.ii;\n  var b = (aabb[0][1] - ro[1]) * ray.ij;\n\n  norm[0] = (a >= b) ?  1 : 0;\n  norm[1] = (b >= a) ? -1 : 0;\n  norm[2] = 0\n\n  return max(a, b);\n};\n\nlerps[classify.PMO] = function lerpPMO(ray, aabb, norm) {\n  var ro = ray.ro;\n\n  var a = (aabb[0][0] - ro[0]) * ray.ii;\n  var b = (aabb[1][1] - ro[1]) * ray.ij;\n\n  norm[0] = (a >= b) ? -1 : 0;\n  norm[1] = (b >= a) ?  1 : 0;\n  norm[2] = 0\n\n  return max(a, b);\n};\n\nlerps[classify.PPO] = function lerpPPO(ray, aabb, norm) {\n  var ro = ray.ro;\n  var lb = aabb[0];\n\n  var a = (lb[0] - ro[0]) * ray.ii;\n  var b = (lb[1] - ro[1]) * ray.ij;\n\n  norm[0] = (a >= b) ? -1 : 0;\n  norm[1] = (b >= a) ? -1 : 0;\n  norm[2] = 0;\n\n  return max(a, b);\n};\n\nlerps[classify.MOO] = function lerpMOO(ray, aabb, norm) {\n  norm[0] = 1;\n  norm[1] = norm[2] = 0;\n  return (aabb[1][0] - ray.ro[0]) * ray.ii;\n};\n\nlerps[classify.POO] = function lerpPOO(ray, aabb, norm) {\n  norm[0] = -1;\n  norm[1] = norm[2] = 0;\n  return (aabb[0][0] - ray.ro[0]) * ray.ii;\n};\n\nlerps[classify.OMO] = function lerpOMO(ray, aabb, norm) {\n  norm[0] = 0;\n  norm[1] = 1;\n  norm[2] = 0;\n  return (aabb[1][1] - ray.ro[1]) * ray.ij;\n};\n\nlerps[classify.OPO] = function lerpOPO(ray, aabb, norm) {\n  norm[0] = 0;\n  norm[1] = -1;\n  norm[2] = 0;\n  return (aabb[0][1] - ray.ro[1]) * ray.ij;\n};\n\nlerps[classify.OOM] = function lerpOOM(ray, aabb, norm) {\n  norm[0] = norm[1] = 0;\n  norm[2] = 1;\n  return (aabb[1][2] - ray.ro[2]) * ray.ik;\n};\n\nlerps[classify.OOP] = function lerpOOP(ray, aabb, norm) {\n  norm[0] = norm[1] = 0;\n  norm[2] = -1;\n  return (aabb[0][2] - ray.ro[2]) * ray.ik;\n}\n\nfunction Ray(ro, rd) {\n  this.ro = [0, 0, 0];\n  this.rd = [0, 0, 0];\n  this.update(ro, rd);\n}\n\nRay.prototype.ii = 0.0;\nRay.prototype.ij = 0.0;\nRay.prototype.ik = 0.0;\nRay.prototype.ibyj = 0.0;\nRay.prototype.jbyi = 0.0;\nRay.prototype.jbyk = 0.0;\nRay.prototype.kbyj = 0.0;\nRay.prototype.ibyk = 0.0;\nRay.prototype.kbyi = 0.0;\nRay.prototype.cxy = 0.0;\nRay.prototype.cxz = 0.0;\nRay.prototype.cyx = 0.0;\nRay.prototype.cyz = 0.0;\nRay.prototype.czx = 0.0;\nRay.prototype.czy = 0.0;\nRay.prototype.classification = 0.0;\nRay.prototype.result = null;\n\nvar scratchNormal = [0, 0, 0];\n\nRay.prototype.intersects =  function rayIntersectsAABB(aabb, computeDistance) {\n  var classification = this.classification;\n  var t = tests[classification];\n  if (t && t(this, aabb[0], aabb[1])) {\n    if (!computeDistance) {\n      return true;\n    }\n\n    var lerp = lerps[classification]\n    var normal = Array.isArray(computeDistance) ? computeDistance : scratchNormal;\n    return lerp && lerp(this, aabb, normal);\n  }\n  return false;\n};\n\nRay.prototype.update = function updateRay(ro, rd) {\n  var r = this;\n  var i = rd[0], j = rd[1], k = rd[2];\n  var x = ro[0], y = ro[1], z = ro[2];\n\n  var tro = r.ro;\n  var trd = r.rd;\n\n  if (i === trd[0] && j === trd[1] && k === trd[2] &&\n      x === tro[0] && y === tro[1] && z === tro[2])\n  {\n    return r;\n  }\n\n  r.ro[0] = x;\n  r.ro[1] = y;\n  r.ro[2] = z;\n  r.rd[0] = i;\n  r.rd[1] = j;\n  r.rd[2] = k;\n\n  var ii = r.ii = (i === 0)?0:1.0/i;\n  var ij = r.ij = (j === 0)?0:1.0/j;\n  var ik = r.ik = (k === 0)?0:1.0/k;\n  //ray slope\n  var ibyj = r.ibyj = i * ij;\n  var jbyi = r.jbyi = j * ii;\n  var jbyk = r.jbyk = j * ik;\n  var kbyj = r.kbyj = k * ij;\n  var ibyk = r.ibyk = i * ik;\n  var kbyi = r.kbyi = k * ii;\n  r.cxy = y - jbyi * x;\n  r.cxz = z - kbyi * x;\n  r.cyx = x - ibyj * y;\n  r.cyz = z - kbyj * y;\n  r.czx = x - ibyk * z;\n  r.czy = y - jbyk * z;\n\n  r.classification = classify(i, j, k);\n  return r;\n};\n\nfunction createRay(rayOrigin, rayDirection) {\n  return new Ray(rayOrigin, rayDirection)\n}\n","module.exports = classify;\n\nfunction sign(a) {\n  return typeof a === 'number' ? a ? a < 0 ? -1 : 1 : a === a ? 0 : 0 : 0\n}\n\nfunction classify(i, j, k) {\n  // sign\n  i = sign(i);\n  j = sign(j);\n  k = sign(k);\n\n  // b00110100 === MPO\n  //    ||||||_ k non-zero (false)\n  //    |||||_ k negative (false)\n  //    ||||_ j non-zero (true)\n  //    |||_ j negative (false)\n  //    ||_ i non-zero (true)\n  //    |_ i negative (true)\n  return (i>>>-1) << 5 | (i&1) << 4 |\n         (j>>>-1) << 3 | (j&1) << 2 |\n         (k>>>-1) << 1 | (k&1);\n}\n\nclassify.MMM = 63; // b00111111\nclassify.MMP = 61; // b00111101\nclassify.MPM = 55; // b00110111\nclassify.MPP = 53; // b00110101\nclassify.PMM = 31; // b00011111\nclassify.PMP = 29; // b00011101\nclassify.PPM = 23; // b00010111\nclassify.PPP = 21; // b00010101\nclassify.POO = 16; // b00010000\nclassify.MOO = 48; // b00110000\nclassify.OPO =  4; // b00000100\nclassify.OMO = 12; // b00001100\nclassify.OOP =  1; // b00000001\nclassify.OOM =  3; // b00000011\nclassify.OMM = 15; // b00001111\nclassify.OMP = 13; // b00001101\nclassify.OPM =  7; // b00000111\nclassify.OPP =  5; // b00000101\nclassify.MOM = 51; // b00110011\nclassify.MOP = 49; // b00110001\nclassify.POM = 19; // b00010011\nclassify.POP = 17; // b00010001\nclassify.MMO = 60; // b00111100\nclassify.MPO = 52; // b00110100\nclassify.PMO = 28; // b00011100\nclassify.PPO = 20; // b00010100\n","/*!\n * The MIT License (MIT)\n * \n * Copyright (c) 2017 Juan Cazala - https://caza.la\n * \n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this software and associated documentation files (the \"Software\"), to deal\n * in the Software without restriction, including without limitation the rights\n * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n * copies of the Software, and to permit persons to whom the Software is\n * furnished to do so, subject to the following conditions:\n * \n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n * \n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n * THE SOFTWARE\n * \n * \n * \n * ********************************************************************************************\n *                                   SYNAPTIC (v1.1.4)\n * ********************************************************************************************\n * \n * Synaptic is a javascript neural network library for node.js and the browser, its generalized\n * algorithm is architecture-free, so you can build and train basically any type of first order\n * or even second order neural network architectures.\n * \n * http://en.wikipedia.org/wiki/Recurrent_neural_network#Second_Order_Recurrent_Neural_Network\n * \n * The library includes a few built-in architectures like multilayer perceptrons, multilayer\n * long-short term memory networks (LSTM) or liquid state machines, and a trainer capable of\n * training any given network, and includes built-in training tasks/tests like solving an XOR,\n * passing a Distracted Sequence Recall test or an Embeded Reber Grammar test.\n * \n * The algorithm implemented by this library has been taken from Derek D. Monner's paper:\n * \n * \n * A generalized LSTM-like training algorithm for second-order recurrent neural networks\n * http://www.overcomplete.net/papers/nn2012.pdf\n * \n * There are references to the equations in that paper commented through the source code.\n * \n */\n(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"synaptic\"] = factory();\n\telse\n\t\troot[\"synaptic\"] = factory();\n})(this, function() {\nreturn /******/ (function(modules) { // webpackBootstrap\n/******/ \t// The module cache\n/******/ \tvar installedModules = {};\n/******/\n/******/ \t// The require function\n/******/ \tfunction __webpack_require__(moduleId) {\n/******/\n/******/ \t\t// Check if module is in cache\n/******/ \t\tif(installedModules[moduleId]) {\n/******/ \t\t\treturn installedModules[moduleId].exports;\n/******/ \t\t}\n/******/ \t\t// Create a new module (and put it into the cache)\n/******/ \t\tvar module = installedModules[moduleId] = {\n/******/ \t\t\ti: moduleId,\n/******/ \t\t\tl: false,\n/******/ \t\t\texports: {}\n/******/ \t\t};\n/******/\n/******/ \t\t// Execute the module function\n/******/ \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n/******/\n/******/ \t\t// Flag the module as loaded\n/******/ \t\tmodule.l = true;\n/******/\n/******/ \t\t// Return the exports of the module\n/******/ \t\treturn module.exports;\n/******/ \t}\n/******/\n/******/\n/******/ \t// expose the modules object (__webpack_modules__)\n/******/ \t__webpack_require__.m = modules;\n/******/\n/******/ \t// expose the module cache\n/******/ \t__webpack_require__.c = installedModules;\n/******/\n/******/ \t// define getter function for harmony exports\n/******/ \t__webpack_require__.d = function(exports, name, getter) {\n/******/ \t\tif(!__webpack_require__.o(exports, name)) {\n/******/ \t\t\tObject.defineProperty(exports, name, {\n/******/ \t\t\t\tconfigurable: false,\n/******/ \t\t\t\tenumerable: true,\n/******/ \t\t\t\tget: getter\n/******/ \t\t\t});\n/******/ \t\t}\n/******/ \t};\n/******/\n/******/ \t// getDefaultExport function for compatibility with non-harmony modules\n/******/ \t__webpack_require__.n = function(module) {\n/******/ \t\tvar getter = module && module.__esModule ?\n/******/ \t\t\tfunction getDefault() { return module['default']; } :\n/******/ \t\t\tfunction getModuleExports() { return module; };\n/******/ \t\t__webpack_require__.d(getter, 'a', getter);\n/******/ \t\treturn getter;\n/******/ \t};\n/******/\n/******/ \t// Object.prototype.hasOwnProperty.call\n/******/ \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n/******/\n/******/ \t// __webpack_public_path__\n/******/ \t__webpack_require__.p = \"\";\n/******/\n/******/ \t// Load entry module and return exports\n/******/ \treturn __webpack_require__(__webpack_require__.s = 4);\n/******/ })\n/************************************************************************/\n/******/ ([\n/* 0 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nvar _LayerConnection = __webpack_require__(6);\n\nvar _LayerConnection2 = _interopRequireDefault(_LayerConnection);\n\nvar _Neuron = __webpack_require__(2);\n\nvar _Neuron2 = _interopRequireDefault(_Neuron);\n\nvar _Network = __webpack_require__(1);\n\nvar _Network2 = _interopRequireDefault(_Network);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n// types of connections\nvar connectionType = {\n  ALL_TO_ALL: \"ALL TO ALL\",\n  ONE_TO_ONE: \"ONE TO ONE\",\n  ALL_TO_ELSE: \"ALL TO ELSE\"\n};\n\n// types of gates\nvar gateType = {\n  INPUT: \"INPUT\",\n  OUTPUT: \"OUTPUT\",\n  ONE_TO_ONE: \"ONE TO ONE\"\n};\n\nvar Layer = function () {\n  function Layer(size) {\n    _classCallCheck(this, Layer);\n\n    this.size = size | 0;\n    this.list = [];\n\n    this.connectedTo = [];\n\n    while (size--) {\n      var neuron = new _Neuron2.default();\n      this.list.push(neuron);\n    }\n  }\n\n  // activates all the neurons in the layer\n\n\n  _createClass(Layer, [{\n    key: 'activate',\n    value: function activate(input) {\n\n      var activations = [];\n\n      if (typeof input != 'undefined') {\n        if (input.length != this.size) throw new Error('INPUT size and LAYER size must be the same to activate!');\n\n        for (var id in this.list) {\n          var neuron = this.list[id];\n          var activation = neuron.activate(input[id]);\n          activations.push(activation);\n        }\n      } else {\n        for (var id in this.list) {\n          var neuron = this.list[id];\n          var activation = neuron.activate();\n          activations.push(activation);\n        }\n      }\n      return activations;\n    }\n\n    // propagates the error on all the neurons of the layer\n\n  }, {\n    key: 'propagate',\n    value: function propagate(rate, target) {\n\n      if (typeof target != 'undefined') {\n        if (target.length != this.size) throw new Error('TARGET size and LAYER size must be the same to propagate!');\n\n        for (var id = this.list.length - 1; id >= 0; id--) {\n          var neuron = this.list[id];\n          neuron.propagate(rate, target[id]);\n        }\n      } else {\n        for (var id = this.list.length - 1; id >= 0; id--) {\n          var neuron = this.list[id];\n          neuron.propagate(rate);\n        }\n      }\n    }\n\n    // projects a connection from this layer to another one\n\n  }, {\n    key: 'project',\n    value: function project(layer, type, weights) {\n\n      if (layer instanceof _Network2.default) layer = layer.layers.input;\n\n      if (layer instanceof Layer) {\n        if (!this.connected(layer)) return new _LayerConnection2.default(this, layer, type, weights);\n      } else throw new Error('Invalid argument, you can only project connections to LAYERS and NETWORKS!');\n    }\n\n    // gates a connection betwenn two layers\n\n  }, {\n    key: 'gate',\n    value: function gate(connection, type) {\n\n      if (type == Layer.gateType.INPUT) {\n        if (connection.to.size != this.size) throw new Error('GATER layer and CONNECTION.TO layer must be the same size in order to gate!');\n\n        for (var id in connection.to.list) {\n          var neuron = connection.to.list[id];\n          var gater = this.list[id];\n          for (var input in neuron.connections.inputs) {\n            var gated = neuron.connections.inputs[input];\n            if (gated.ID in connection.connections) gater.gate(gated);\n          }\n        }\n      } else if (type == Layer.gateType.OUTPUT) {\n        if (connection.from.size != this.size) throw new Error('GATER layer and CONNECTION.FROM layer must be the same size in order to gate!');\n\n        for (var id in connection.from.list) {\n          var neuron = connection.from.list[id];\n          var gater = this.list[id];\n          for (var projected in neuron.connections.projected) {\n            var gated = neuron.connections.projected[projected];\n            if (gated.ID in connection.connections) gater.gate(gated);\n          }\n        }\n      } else if (type == Layer.gateType.ONE_TO_ONE) {\n        if (connection.size != this.size) throw new Error('The number of GATER UNITS must be the same as the number of CONNECTIONS to gate!');\n\n        for (var id in connection.list) {\n          var gater = this.list[id];\n          var gated = connection.list[id];\n          gater.gate(gated);\n        }\n      }\n      connection.gatedfrom.push({ layer: this, type: type });\n    }\n\n    // true or false whether the whole layer is self-connected or not\n\n  }, {\n    key: 'selfconnected',\n    value: function selfconnected() {\n\n      for (var id in this.list) {\n        var neuron = this.list[id];\n        if (!neuron.selfconnected()) return false;\n      }\n      return true;\n    }\n\n    // true of false whether the layer is connected to another layer (parameter) or not\n\n  }, {\n    key: 'connected',\n    value: function connected(layer) {\n      // Check if ALL to ALL connection\n      var connections = 0;\n      for (var here in this.list) {\n        for (var there in layer.list) {\n          var from = this.list[here];\n          var to = layer.list[there];\n          var connected = from.connected(to);\n          if (connected.type == 'projected') connections++;\n        }\n      }\n      if (connections == this.size * layer.size) return Layer.connectionType.ALL_TO_ALL;\n\n      // Check if ONE to ONE connection\n      connections = 0;\n      for (var neuron in this.list) {\n        var from = this.list[neuron];\n        var to = layer.list[neuron];\n        var connected = from.connected(to);\n        if (connected.type == 'projected') connections++;\n      }\n      if (connections == this.size) return Layer.connectionType.ONE_TO_ONE;\n    }\n\n    // clears all the neuorns in the layer\n\n  }, {\n    key: 'clear',\n    value: function clear() {\n      for (var id in this.list) {\n        var neuron = this.list[id];\n        neuron.clear();\n      }\n    }\n\n    // resets all the neurons in the layer\n\n  }, {\n    key: 'reset',\n    value: function reset() {\n      for (var id in this.list) {\n        var neuron = this.list[id];\n        neuron.reset();\n      }\n    }\n\n    // returns all the neurons in the layer (array)\n\n  }, {\n    key: 'neurons',\n    value: function neurons() {\n      return this.list;\n    }\n\n    // adds a neuron to the layer\n\n  }, {\n    key: 'add',\n    value: function add(neuron) {\n      neuron = neuron || new _Neuron2.default();\n      this.list.push(neuron);\n      this.size++;\n    }\n  }, {\n    key: 'set',\n    value: function set(options) {\n      options = options || {};\n\n      for (var i in this.list) {\n        var neuron = this.list[i];\n        if (options.label) neuron.label = options.label + '_' + neuron.ID;\n        if (options.squash) neuron.squash = options.squash;\n        if (options.bias) neuron.bias = options.bias;\n      }\n      return this;\n    }\n  }]);\n\n  return Layer;\n}();\n\nLayer.connectionType = connectionType;\nLayer.gateType = gateType;\nexports.default = Layer;\n\n/***/ }),\n/* 1 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _typeof = typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\" ? function (obj) { return typeof obj; } : function (obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; };\n\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nvar _Neuron = __webpack_require__(2);\n\nvar _Neuron2 = _interopRequireDefault(_Neuron);\n\nvar _Layer = __webpack_require__(0);\n\nvar _Layer2 = _interopRequireDefault(_Layer);\n\nvar _Trainer = __webpack_require__(3);\n\nvar _Trainer2 = _interopRequireDefault(_Trainer);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Network = function () {\n  function Network(layers) {\n    _classCallCheck(this, Network);\n\n    if (typeof layers != 'undefined') {\n      this.layers = {\n        input: layers.input || null,\n        hidden: layers.hidden || [],\n        output: layers.output || null\n      };\n      this.optimized = null;\n    }\n  }\n\n  // feed-forward activation of all the layers to produce an ouput\n\n\n  _createClass(Network, [{\n    key: 'activate',\n    value: function activate(input) {\n      if (this.optimized === false) {\n        this.layers.input.activate(input);\n        for (var i = 0; i < this.layers.hidden.length; i++) {\n          this.layers.hidden[i].activate();\n        }return this.layers.output.activate();\n      } else {\n        if (this.optimized == null) this.optimize();\n        return this.optimized.activate(input);\n      }\n    }\n\n    // back-propagate the error thru the network\n\n  }, {\n    key: 'propagate',\n    value: function propagate(rate, target) {\n      if (this.optimized === false) {\n        this.layers.output.propagate(rate, target);\n        for (var i = this.layers.hidden.length - 1; i >= 0; i--) {\n          this.layers.hidden[i].propagate(rate);\n        }\n      } else {\n        if (this.optimized == null) this.optimize();\n        this.optimized.propagate(rate, target);\n      }\n    }\n\n    // project a connection to another unit (either a network or a layer)\n\n  }, {\n    key: 'project',\n    value: function project(unit, type, weights) {\n      if (this.optimized) this.optimized.reset();\n\n      if (unit instanceof Network) return this.layers.output.project(unit.layers.input, type, weights);\n\n      if (unit instanceof _Layer2.default) return this.layers.output.project(unit, type, weights);\n\n      throw new Error('Invalid argument, you can only project connections to LAYERS and NETWORKS!');\n    }\n\n    // let this network gate a connection\n\n  }, {\n    key: 'gate',\n    value: function gate(connection, type) {\n      if (this.optimized) this.optimized.reset();\n      this.layers.output.gate(connection, type);\n    }\n\n    // clear all elegibility traces and extended elegibility traces (the network forgets its context, but not what was trained)\n\n  }, {\n    key: 'clear',\n    value: function clear() {\n      this.restore();\n\n      var inputLayer = this.layers.input,\n          outputLayer = this.layers.output;\n\n      inputLayer.clear();\n      for (var i = 0; i < this.layers.hidden.length; i++) {\n        this.layers.hidden[i].clear();\n      }\n      outputLayer.clear();\n\n      if (this.optimized) this.optimized.reset();\n    }\n\n    // reset all weights and clear all traces (ends up like a new network)\n\n  }, {\n    key: 'reset',\n    value: function reset() {\n      this.restore();\n\n      var inputLayer = this.layers.input,\n          outputLayer = this.layers.output;\n\n      inputLayer.reset();\n      for (var i = 0; i < this.layers.hidden.length; i++) {\n        this.layers.hidden[i].reset();\n      }\n      outputLayer.reset();\n\n      if (this.optimized) this.optimized.reset();\n    }\n\n    // hardcodes the behaviour of the whole network into a single optimized function\n\n  }, {\n    key: 'optimize',\n    value: function optimize() {\n      var that = this;\n      var optimized = {};\n      var neurons = this.neurons();\n\n      for (var i = 0; i < neurons.length; i++) {\n        var neuron = neurons[i].neuron;\n        var layer = neurons[i].layer;\n        while (neuron.neuron) {\n          neuron = neuron.neuron;\n        }optimized = neuron.optimize(optimized, layer);\n      }\n\n      for (var i = 0; i < optimized.propagation_sentences.length; i++) {\n        optimized.propagation_sentences[i].reverse();\n      }optimized.propagation_sentences.reverse();\n\n      var hardcode = '';\n      hardcode += 'var F = Float64Array ? new Float64Array(' + optimized.memory + ') : []; ';\n      for (var i in optimized.variables) {\n        hardcode += 'F[' + optimized.variables[i].id + '] = ' + (optimized.variables[i].value || 0) + '; ';\n      }hardcode += 'var activate = function(input){\\n';\n      for (var i = 0; i < optimized.inputs.length; i++) {\n        hardcode += 'F[' + optimized.inputs[i] + '] = input[' + i + ']; ';\n      }for (var i = 0; i < optimized.activation_sentences.length; i++) {\n        if (optimized.activation_sentences[i].length > 0) {\n          for (var j = 0; j < optimized.activation_sentences[i].length; j++) {\n            hardcode += optimized.activation_sentences[i][j].join(' ');\n            hardcode += optimized.trace_sentences[i][j].join(' ');\n          }\n        }\n      }\n      hardcode += ' var output = []; ';\n      for (var i = 0; i < optimized.outputs.length; i++) {\n        hardcode += 'output[' + i + '] = F[' + optimized.outputs[i] + ']; ';\n      }hardcode += 'return output; }; ';\n      hardcode += 'var propagate = function(rate, target){\\n';\n      hardcode += 'F[' + optimized.variables.rate.id + '] = rate; ';\n      for (var i = 0; i < optimized.targets.length; i++) {\n        hardcode += 'F[' + optimized.targets[i] + '] = target[' + i + ']; ';\n      }for (var i = 0; i < optimized.propagation_sentences.length; i++) {\n        for (var j = 0; j < optimized.propagation_sentences[i].length; j++) {\n          hardcode += optimized.propagation_sentences[i][j].join(' ') + ' ';\n        }\n      }hardcode += ' };\\n';\n      hardcode += 'var ownership = function(memoryBuffer){\\nF = memoryBuffer;\\nthis.memory = F;\\n};\\n';\n      hardcode += 'return {\\nmemory: F,\\nactivate: activate,\\npropagate: propagate,\\nownership: ownership\\n};';\n      hardcode = hardcode.split(';').join(';\\n');\n\n      var constructor = new Function(hardcode);\n\n      var network = constructor();\n      network.data = {\n        variables: optimized.variables,\n        activate: optimized.activation_sentences,\n        propagate: optimized.propagation_sentences,\n        trace: optimized.trace_sentences,\n        inputs: optimized.inputs,\n        outputs: optimized.outputs,\n        check_activation: this.activate,\n        check_propagation: this.propagate\n      };\n\n      network.reset = function () {\n        if (that.optimized) {\n          that.optimized = null;\n          that.activate = network.data.check_activation;\n          that.propagate = network.data.check_propagation;\n        }\n      };\n\n      this.optimized = network;\n      this.activate = network.activate;\n      this.propagate = network.propagate;\n    }\n\n    // restores all the values from the optimized network the their respective objects in order to manipulate the network\n\n  }, {\n    key: 'restore',\n    value: function restore() {\n      if (!this.optimized) return;\n\n      var optimized = this.optimized;\n\n      var getValue = function getValue() {\n        var args = Array.prototype.slice.call(arguments);\n\n        var unit = args.shift();\n        var prop = args.pop();\n\n        var id = prop + '_';\n        for (var property in args) {\n          id += args[property] + '_';\n        }id += unit.ID;\n\n        var memory = optimized.memory;\n        var variables = optimized.data.variables;\n\n        if (id in variables) return memory[variables[id].id];\n        return 0;\n      };\n\n      var list = this.neurons();\n\n      // link id's to positions in the array\n      for (var i = 0; i < list.length; i++) {\n        var neuron = list[i].neuron;\n        while (neuron.neuron) {\n          neuron = neuron.neuron;\n        }neuron.state = getValue(neuron, 'state');\n        neuron.old = getValue(neuron, 'old');\n        neuron.activation = getValue(neuron, 'activation');\n        neuron.bias = getValue(neuron, 'bias');\n\n        for (var input in neuron.trace.elegibility) {\n          neuron.trace.elegibility[input] = getValue(neuron, 'trace', 'elegibility', input);\n        }for (var gated in neuron.trace.extended) {\n          for (var input in neuron.trace.extended[gated]) {\n            neuron.trace.extended[gated][input] = getValue(neuron, 'trace', 'extended', gated, input);\n          }\n        } // get connections\n        for (var j in neuron.connections.projected) {\n          var connection = neuron.connections.projected[j];\n          connection.weight = getValue(connection, 'weight');\n          connection.gain = getValue(connection, 'gain');\n        }\n      }\n    }\n\n    // returns all the neurons in the network\n\n  }, {\n    key: 'neurons',\n    value: function neurons() {\n      var neurons = [];\n\n      var inputLayer = this.layers.input.neurons(),\n          outputLayer = this.layers.output.neurons();\n\n      for (var i = 0; i < inputLayer.length; i++) {\n        neurons.push({\n          neuron: inputLayer[i],\n          layer: 'input'\n        });\n      }\n\n      for (var i = 0; i < this.layers.hidden.length; i++) {\n        var hiddenLayer = this.layers.hidden[i].neurons();\n        for (var j = 0; j < hiddenLayer.length; j++) {\n          neurons.push({\n            neuron: hiddenLayer[j],\n            layer: i\n          });\n        }\n      }\n\n      for (var i = 0; i < outputLayer.length; i++) {\n        neurons.push({\n          neuron: outputLayer[i],\n          layer: 'output'\n        });\n      }\n\n      return neurons;\n    }\n\n    // returns number of inputs of the network\n\n  }, {\n    key: 'inputs',\n    value: function inputs() {\n      return this.layers.input.size;\n    }\n\n    // returns number of outputs of hte network\n\n  }, {\n    key: 'outputs',\n    value: function outputs() {\n      return this.layers.output.size;\n    }\n\n    // sets the layers of the network\n\n  }, {\n    key: 'set',\n    value: function set(layers) {\n      this.layers = {\n        input: layers.input || null,\n        hidden: layers.hidden || [],\n        output: layers.output || null\n      };\n      if (this.optimized) this.optimized.reset();\n    }\n  }, {\n    key: 'setOptimize',\n    value: function setOptimize(bool) {\n      this.restore();\n      if (this.optimized) this.optimized.reset();\n      this.optimized = bool ? null : false;\n    }\n\n    // returns a json that represents all the neurons and connections of the network\n\n  }, {\n    key: 'toJSON',\n    value: function toJSON(ignoreTraces) {\n      this.restore();\n\n      var list = this.neurons();\n      var neurons = [];\n      var connections = [];\n\n      // link id's to positions in the array\n      var ids = {};\n      for (var i = 0; i < list.length; i++) {\n        var neuron = list[i].neuron;\n        while (neuron.neuron) {\n          neuron = neuron.neuron;\n        }ids[neuron.ID] = i;\n\n        var copy = {\n          trace: {\n            elegibility: {},\n            extended: {}\n          },\n          state: neuron.state,\n          old: neuron.old,\n          activation: neuron.activation,\n          bias: neuron.bias,\n          layer: list[i].layer\n        };\n\n        copy.squash = neuron.squash == _Neuron2.default.squash.LOGISTIC ? 'LOGISTIC' : neuron.squash == _Neuron2.default.squash.TANH ? 'TANH' : neuron.squash == _Neuron2.default.squash.IDENTITY ? 'IDENTITY' : neuron.squash == _Neuron2.default.squash.HLIM ? 'HLIM' : neuron.squash == _Neuron2.default.squash.RELU ? 'RELU' : null;\n\n        neurons.push(copy);\n      }\n\n      for (var i = 0; i < list.length; i++) {\n        var neuron = list[i].neuron;\n        while (neuron.neuron) {\n          neuron = neuron.neuron;\n        }for (var j in neuron.connections.projected) {\n          var connection = neuron.connections.projected[j];\n          connections.push({\n            from: ids[connection.from.ID],\n            to: ids[connection.to.ID],\n            weight: connection.weight,\n            gater: connection.gater ? ids[connection.gater.ID] : null\n          });\n        }\n        if (neuron.selfconnected()) {\n          connections.push({\n            from: ids[neuron.ID],\n            to: ids[neuron.ID],\n            weight: neuron.selfconnection.weight,\n            gater: neuron.selfconnection.gater ? ids[neuron.selfconnection.gater.ID] : null\n          });\n        }\n      }\n\n      return {\n        neurons: neurons,\n        connections: connections\n      };\n    }\n\n    // export the topology into dot language which can be visualized as graphs using dot\n    /* example: ... console.log(net.toDotLang());\n                $ node example.js > example.dot\n                $ dot example.dot -Tpng > out.png\n    */\n\n  }, {\n    key: 'toDot',\n    value: function toDot(edgeConnection) {\n      if (!(typeof edgeConnection === 'undefined' ? 'undefined' : _typeof(edgeConnection))) edgeConnection = false;\n      var code = 'digraph nn {\\n    rankdir = BT\\n';\n      var layers = [this.layers.input].concat(this.layers.hidden, this.layers.output);\n      for (var i = 0; i < layers.length; i++) {\n        for (var j = 0; j < layers[i].connectedTo.length; j++) {\n          // projections\n          var connection = layers[i].connectedTo[j];\n          var layerTo = connection.to;\n          var size = connection.size;\n          var layerID = layers.indexOf(layers[i]);\n          var layerToID = layers.indexOf(layerTo);\n          /* http://stackoverflow.com/questions/26845540/connect-edges-with-graph-dot\n           * DOT does not support edge-to-edge connections\n           * This workaround produces somewhat weird graphs ...\n          */\n          if (edgeConnection) {\n            if (connection.gatedfrom.length) {\n              var fakeNode = 'fake' + layerID + '_' + layerToID;\n              code += '    ' + fakeNode + ' [label = \"\", shape = point, width = 0.01, height = 0.01]\\n';\n              code += '    ' + layerID + ' -> ' + fakeNode + ' [label = ' + size + ', arrowhead = none]\\n';\n              code += '    ' + fakeNode + ' -> ' + layerToID + '\\n';\n            } else code += '    ' + layerID + ' -> ' + layerToID + ' [label = ' + size + ']\\n';\n            for (var from in connection.gatedfrom) {\n              // gatings\n              var layerfrom = connection.gatedfrom[from].layer;\n              var layerfromID = layers.indexOf(layerfrom);\n              code += '    ' + layerfromID + ' -> ' + fakeNode + ' [color = blue]\\n';\n            }\n          } else {\n            code += '    ' + layerID + ' -> ' + layerToID + ' [label = ' + size + ']\\n';\n            for (var from in connection.gatedfrom) {\n              // gatings\n              var layerfrom = connection.gatedfrom[from].layer;\n              var layerfromID = layers.indexOf(layerfrom);\n              code += '    ' + layerfromID + ' -> ' + layerToID + ' [color = blue]\\n';\n            }\n          }\n        }\n      }\n      code += '}\\n';\n      return {\n        code: code,\n        link: 'https://chart.googleapis.com/chart?chl=' + escape(code.replace('/ /g', '+')) + '&cht=gv'\n      };\n    }\n\n    // returns a function that works as the activation of the network and can be used without depending on the library\n\n  }, {\n    key: 'standalone',\n    value: function standalone() {\n      if (!this.optimized) this.optimize();\n\n      var data = this.optimized.data;\n\n      // build activation function\n      var activation = 'function (input) {\\n';\n\n      // build inputs\n      for (var i = 0; i < data.inputs.length; i++) {\n        activation += 'F[' + data.inputs[i] + '] = input[' + i + '];\\n';\n      } // build network activation\n      for (var i = 0; i < data.activate.length; i++) {\n        // shouldn't this be layer?\n        for (var j = 0; j < data.activate[i].length; j++) {\n          activation += data.activate[i][j].join('') + '\\n';\n        }\n      }\n\n      // build outputs\n      activation += 'var output = [];\\n';\n      for (var i = 0; i < data.outputs.length; i++) {\n        activation += 'output[' + i + '] = F[' + data.outputs[i] + '];\\n';\n      }activation += 'return output;\\n}';\n\n      // reference all the positions in memory\n      var memory = activation.match(/F\\[(\\d+)\\]/g);\n      var dimension = 0;\n      var ids = {};\n\n      for (var i = 0; i < memory.length; i++) {\n        var tmp = memory[i].match(/\\d+/)[0];\n        if (!(tmp in ids)) {\n          ids[tmp] = dimension++;\n        }\n      }\n      var hardcode = 'F = {\\n';\n\n      for (var i in ids) {\n        hardcode += ids[i] + ': ' + this.optimized.memory[i] + ',\\n';\n      }hardcode = hardcode.substring(0, hardcode.length - 2) + '\\n};\\n';\n      hardcode = 'var run = ' + activation.replace(/F\\[(\\d+)]/g, function (index) {\n        return 'F[' + ids[index.match(/\\d+/)[0]] + ']';\n      }).replace('{\\n', '{\\n' + hardcode + '') + ';\\n';\n      hardcode += 'return run';\n\n      // return standalone function\n      return new Function(hardcode)();\n    }\n\n    // Return a HTML5 WebWorker specialized on training the network stored in `memory`.\n    // Train based on the given dataSet and options.\n    // The worker returns the updated `memory` when done.\n\n  }, {\n    key: 'worker',\n    value: function worker(memory, set, options) {\n      // Copy the options and set defaults (options might be different for each worker)\n      var workerOptions = {};\n      if (options) workerOptions = options;\n      workerOptions.rate = workerOptions.rate || .2;\n      workerOptions.iterations = workerOptions.iterations || 100000;\n      workerOptions.error = workerOptions.error || .005;\n      workerOptions.cost = workerOptions.cost || null;\n      workerOptions.crossValidate = workerOptions.crossValidate || null;\n\n      // Cost function might be different for each worker\n      var costFunction = '// REPLACED BY WORKER\\nvar cost = ' + (options && options.cost || this.cost || _Trainer2.default.cost.MSE) + ';\\n';\n      var workerFunction = Network.getWorkerSharedFunctions();\n      workerFunction = workerFunction.replace(/var cost = options && options\\.cost \\|\\| this\\.cost \\|\\| Trainer\\.cost\\.MSE;/g, costFunction);\n\n      // Set what we do when training is finished\n      workerFunction = workerFunction.replace('return results;', 'postMessage({action: \"done\", message: results, memoryBuffer: F}, [F.buffer]);');\n\n      // Replace log with postmessage\n      workerFunction = workerFunction.replace('console.log(\\'iterations\\', iterations, \\'error\\', error, \\'rate\\', currentRate)', 'postMessage({action: \\'log\\', message: {\\n' + 'iterations: iterations,\\n' + 'error: error,\\n' + 'rate: currentRate\\n' + '}\\n' + '})');\n\n      // Replace schedule with postmessage\n      workerFunction = workerFunction.replace('abort = this.schedule.do({ error: error, iterations: iterations, rate: currentRate })', 'postMessage({action: \\'schedule\\', message: {\\n' + 'iterations: iterations,\\n' + 'error: error,\\n' + 'rate: currentRate\\n' + '}\\n' + '})');\n\n      if (!this.optimized) this.optimize();\n\n      var hardcode = 'var inputs = ' + this.optimized.data.inputs.length + ';\\n';\n      hardcode += 'var outputs = ' + this.optimized.data.outputs.length + ';\\n';\n      hardcode += 'var F =  new Float64Array([' + this.optimized.memory.toString() + ']);\\n';\n      hardcode += 'var activate = ' + this.optimized.activate.toString() + ';\\n';\n      hardcode += 'var propagate = ' + this.optimized.propagate.toString() + ';\\n';\n      hardcode += 'onmessage = function(e) {\\n' + 'if (e.data.action == \\'startTraining\\') {\\n' + 'train(' + JSON.stringify(set) + ',' + JSON.stringify(workerOptions) + ');\\n' + '}\\n' + '}';\n\n      var workerSourceCode = workerFunction + '\\n' + hardcode;\n      var blob = new Blob([workerSourceCode]);\n      var blobURL = window.URL.createObjectURL(blob);\n\n      return new Worker(blobURL);\n    }\n\n    // returns a copy of the network\n\n  }, {\n    key: 'clone',\n    value: function clone() {\n      return Network.fromJSON(this.toJSON());\n    }\n\n    /**\n     * Creates a static String to store the source code of the functions\n     *  that are identical for all the workers (train, _trainSet, test)\n     *\n     * @return {String} Source code that can train a network inside a worker.\n     * @static\n     */\n\n  }], [{\n    key: 'getWorkerSharedFunctions',\n    value: function getWorkerSharedFunctions() {\n      // If we already computed the source code for the shared functions\n      if (typeof Network._SHARED_WORKER_FUNCTIONS !== 'undefined') return Network._SHARED_WORKER_FUNCTIONS;\n\n      // Otherwise compute and return the source code\n      // We compute them by simply copying the source code of the train, _trainSet and test functions\n      //  using the .toString() method\n\n      // Load and name the train function\n      var train_f = _Trainer2.default.prototype.train.toString();\n      train_f = train_f.replace(/this._trainSet/g, '_trainSet');\n      train_f = train_f.replace(/this.test/g, 'test');\n      train_f = train_f.replace(/this.crossValidate/g, 'crossValidate');\n      train_f = train_f.replace('crossValidate = true', '// REMOVED BY WORKER');\n\n      // Load and name the _trainSet function\n      var _trainSet_f = _Trainer2.default.prototype._trainSet.toString().replace(/this.network./g, '');\n\n      // Load and name the test function\n      var test_f = _Trainer2.default.prototype.test.toString().replace(/this.network./g, '');\n\n      return Network._SHARED_WORKER_FUNCTIONS = train_f + '\\n' + _trainSet_f + '\\n' + test_f;\n    }\n  }, {\n    key: 'fromJSON',\n    value: function fromJSON(json) {\n      var neurons = [];\n\n      var layers = {\n        input: new _Layer2.default(),\n        hidden: [],\n        output: new _Layer2.default()\n      };\n\n      for (var i = 0; i < json.neurons.length; i++) {\n        var config = json.neurons[i];\n\n        var neuron = new _Neuron2.default();\n        neuron.trace.elegibility = {};\n        neuron.trace.extended = {};\n        neuron.state = config.state;\n        neuron.old = config.old;\n        neuron.activation = config.activation;\n        neuron.bias = config.bias;\n        neuron.squash = config.squash in _Neuron2.default.squash ? _Neuron2.default.squash[config.squash] : _Neuron2.default.squash.LOGISTIC;\n        neurons.push(neuron);\n\n        if (config.layer == 'input') layers.input.add(neuron);else if (config.layer == 'output') layers.output.add(neuron);else {\n          if (typeof layers.hidden[config.layer] == 'undefined') layers.hidden[config.layer] = new _Layer2.default();\n          layers.hidden[config.layer].add(neuron);\n        }\n      }\n\n      for (var i = 0; i < json.connections.length; i++) {\n        var config = json.connections[i];\n        var from = neurons[config.from];\n        var to = neurons[config.to];\n        var weight = config.weight;\n        var gater = neurons[config.gater];\n\n        var connection = from.project(to, weight);\n        if (gater) gater.gate(connection);\n      }\n\n      return new Network(layers);\n    }\n  }]);\n\n  return Network;\n}();\n\nexports.default = Network;\n\n/***/ }),\n/* 2 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nvar _Connection = __webpack_require__(5);\n\nvar _Connection2 = _interopRequireDefault(_Connection);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar neurons = 0;\n\n// squashing functions\nvar squash = {\n  // eq. 5 & 5'\n  LOGISTIC: function LOGISTIC(x, derivate) {\n    var fx = 1 / (1 + Math.exp(-x));\n    if (!derivate) return fx;\n    return fx * (1 - fx);\n  },\n  TANH: function TANH(x, derivate) {\n    if (derivate) return 1 - Math.pow(Math.tanh(x), 2);\n    return Math.tanh(x);\n  },\n  IDENTITY: function IDENTITY(x, derivate) {\n    return derivate ? 1 : x;\n  },\n  HLIM: function HLIM(x, derivate) {\n    return derivate ? 1 : x > 0 ? 1 : 0;\n  },\n  RELU: function RELU(x, derivate) {\n    if (derivate) return x > 0 ? 1 : 0;\n    return x > 0 ? x : 0;\n  }\n};\n\nvar Neuron = function () {\n  function Neuron() {\n    _classCallCheck(this, Neuron);\n\n    this.ID = Neuron.uid();\n\n    this.connections = {\n      inputs: {},\n      projected: {},\n      gated: {}\n    };\n    this.error = {\n      responsibility: 0,\n      projected: 0,\n      gated: 0\n    };\n    this.trace = {\n      elegibility: {},\n      extended: {},\n      influences: {}\n    };\n    this.state = 0;\n    this.old = 0;\n    this.activation = 0;\n    this.selfconnection = new _Connection2.default(this, this, 0); // weight = 0 -> not connected\n    this.squash = Neuron.squash.LOGISTIC;\n    this.neighboors = {};\n    this.bias = Math.random() * .2 - .1;\n  }\n\n  // activate the neuron\n\n\n  _createClass(Neuron, [{\n    key: 'activate',\n    value: function activate(input) {\n      // activation from enviroment (for input neurons)\n      if (typeof input != 'undefined') {\n        this.activation = input;\n        this.derivative = 0;\n        this.bias = 0;\n        return this.activation;\n      }\n\n      // old state\n      this.old = this.state;\n\n      // eq. 15\n      this.state = this.selfconnection.gain * this.selfconnection.weight * this.state + this.bias;\n\n      for (var i in this.connections.inputs) {\n        var input = this.connections.inputs[i];\n        this.state += input.from.activation * input.weight * input.gain;\n      }\n\n      // eq. 16\n      this.activation = this.squash(this.state);\n\n      // f'(s)\n      this.derivative = this.squash(this.state, true);\n\n      // update traces\n      var influences = [];\n      for (var id in this.trace.extended) {\n        // extended elegibility trace\n        var neuron = this.neighboors[id];\n\n        // if gated neuron's selfconnection is gated by this unit, the influence keeps track of the neuron's old state\n        var influence = neuron.selfconnection.gater == this ? neuron.old : 0;\n\n        // index runs over all the incoming connections to the gated neuron that are gated by this unit\n        for (var incoming in this.trace.influences[neuron.ID]) {\n          // captures the effect that has an input connection to this unit, on a neuron that is gated by this unit\n          influence += this.trace.influences[neuron.ID][incoming].weight * this.trace.influences[neuron.ID][incoming].from.activation;\n        }\n        influences[neuron.ID] = influence;\n      }\n\n      for (var i in this.connections.inputs) {\n        var input = this.connections.inputs[i];\n\n        // elegibility trace - Eq. 17\n        this.trace.elegibility[input.ID] = this.selfconnection.gain * this.selfconnection.weight * this.trace.elegibility[input.ID] + input.gain * input.from.activation;\n\n        for (var id in this.trace.extended) {\n          // extended elegibility trace\n          var xtrace = this.trace.extended[id];\n          var neuron = this.neighboors[id];\n          var influence = influences[neuron.ID];\n\n          // eq. 18\n          xtrace[input.ID] = neuron.selfconnection.gain * neuron.selfconnection.weight * xtrace[input.ID] + this.derivative * this.trace.elegibility[input.ID] * influence;\n        }\n      }\n\n      //  update gated connection's gains\n      for (var connection in this.connections.gated) {\n        this.connections.gated[connection].gain = this.activation;\n      }\n\n      return this.activation;\n    }\n\n    // back-propagate the error\n\n  }, {\n    key: 'propagate',\n    value: function propagate(rate, target) {\n      // error accumulator\n      var error = 0;\n\n      // whether or not this neuron is in the output layer\n      var isOutput = typeof target != 'undefined';\n\n      // output neurons get their error from the enviroment\n      if (isOutput) this.error.responsibility = this.error.projected = target - this.activation; // Eq. 10\n\n      else // the rest of the neuron compute their error responsibilities by backpropagation\n        {\n          // error responsibilities from all the connections projected from this neuron\n          for (var id in this.connections.projected) {\n            var connection = this.connections.projected[id];\n            var neuron = connection.to;\n            // Eq. 21\n            error += neuron.error.responsibility * connection.gain * connection.weight;\n          }\n\n          // projected error responsibility\n          this.error.projected = this.derivative * error;\n\n          error = 0;\n          // error responsibilities from all the connections gated by this neuron\n          for (var id in this.trace.extended) {\n            var neuron = this.neighboors[id]; // gated neuron\n            var influence = neuron.selfconnection.gater == this ? neuron.old : 0; // if gated neuron's selfconnection is gated by this neuron\n\n            // index runs over all the connections to the gated neuron that are gated by this neuron\n            for (var input in this.trace.influences[id]) {\n              // captures the effect that the input connection of this neuron have, on a neuron which its input/s is/are gated by this neuron\n              influence += this.trace.influences[id][input].weight * this.trace.influences[neuron.ID][input].from.activation;\n            }\n            // eq. 22\n            error += neuron.error.responsibility * influence;\n          }\n\n          // gated error responsibility\n          this.error.gated = this.derivative * error;\n\n          // error responsibility - Eq. 23\n          this.error.responsibility = this.error.projected + this.error.gated;\n        }\n\n      // learning rate\n      rate = rate || .1;\n\n      // adjust all the neuron's incoming connections\n      for (var id in this.connections.inputs) {\n        var input = this.connections.inputs[id];\n\n        // Eq. 24\n        var gradient = this.error.projected * this.trace.elegibility[input.ID];\n        for (var id in this.trace.extended) {\n          var neuron = this.neighboors[id];\n          gradient += neuron.error.responsibility * this.trace.extended[neuron.ID][input.ID];\n        }\n        input.weight += rate * gradient; // adjust weights - aka learn\n      }\n\n      // adjust bias\n      this.bias += rate * this.error.responsibility;\n    }\n  }, {\n    key: 'project',\n    value: function project(neuron, weight) {\n      // self-connection\n      if (neuron == this) {\n        this.selfconnection.weight = 1;\n        return this.selfconnection;\n      }\n\n      // check if connection already exists\n      var connected = this.connected(neuron);\n      if (connected && connected.type == 'projected') {\n        // update connection\n        if (typeof weight != 'undefined') connected.connection.weight = weight;\n        // return existing connection\n        return connected.connection;\n      } else {\n        // create a new connection\n        var connection = new _Connection2.default(this, neuron, weight);\n      }\n\n      // reference all the connections and traces\n      this.connections.projected[connection.ID] = connection;\n      this.neighboors[neuron.ID] = neuron;\n      neuron.connections.inputs[connection.ID] = connection;\n      neuron.trace.elegibility[connection.ID] = 0;\n\n      for (var id in neuron.trace.extended) {\n        var trace = neuron.trace.extended[id];\n        trace[connection.ID] = 0;\n      }\n\n      return connection;\n    }\n  }, {\n    key: 'gate',\n    value: function gate(connection) {\n      // add connection to gated list\n      this.connections.gated[connection.ID] = connection;\n\n      var neuron = connection.to;\n      if (!(neuron.ID in this.trace.extended)) {\n        // extended trace\n        this.neighboors[neuron.ID] = neuron;\n        var xtrace = this.trace.extended[neuron.ID] = {};\n        for (var id in this.connections.inputs) {\n          var input = this.connections.inputs[id];\n          xtrace[input.ID] = 0;\n        }\n      }\n\n      // keep track\n      if (neuron.ID in this.trace.influences) this.trace.influences[neuron.ID].push(connection);else this.trace.influences[neuron.ID] = [connection];\n\n      // set gater\n      connection.gater = this;\n    }\n\n    // returns true or false whether the neuron is self-connected or not\n\n  }, {\n    key: 'selfconnected',\n    value: function selfconnected() {\n      return this.selfconnection.weight !== 0;\n    }\n\n    // returns true or false whether the neuron is connected to another neuron (parameter)\n\n  }, {\n    key: 'connected',\n    value: function connected(neuron) {\n      var result = {\n        type: null,\n        connection: false\n      };\n\n      if (this == neuron) {\n        if (this.selfconnected()) {\n          result.type = 'selfconnection';\n          result.connection = this.selfconnection;\n          return result;\n        } else return false;\n      }\n\n      for (var type in this.connections) {\n        for (var connection in this.connections[type]) {\n          var connection = this.connections[type][connection];\n          if (connection.to == neuron) {\n            result.type = type;\n            result.connection = connection;\n            return result;\n          } else if (connection.from == neuron) {\n            result.type = type;\n            result.connection = connection;\n            return result;\n          }\n        }\n      }\n\n      return false;\n    }\n\n    // clears all the traces (the neuron forgets it's context, but the connections remain intact)\n\n  }, {\n    key: 'clear',\n    value: function clear() {\n      for (var trace in this.trace.elegibility) {\n        this.trace.elegibility[trace] = 0;\n      }\n\n      for (var trace in this.trace.extended) {\n        for (var extended in this.trace.extended[trace]) {\n          this.trace.extended[trace][extended] = 0;\n        }\n      }\n\n      this.error.responsibility = this.error.projected = this.error.gated = 0;\n    }\n\n    // all the connections are randomized and the traces are cleared\n\n  }, {\n    key: 'reset',\n    value: function reset() {\n      this.clear();\n\n      for (var type in this.connections) {\n        for (var connection in this.connections[type]) {\n          this.connections[type][connection].weight = Math.random() * .2 - .1;\n        }\n      }\n\n      this.bias = Math.random() * .2 - .1;\n      this.old = this.state = this.activation = 0;\n    }\n\n    // hardcodes the behaviour of the neuron into an optimized function\n\n  }, {\n    key: 'optimize',\n    value: function optimize(optimized, layer) {\n\n      optimized = optimized || {};\n      var store_activation = [];\n      var store_trace = [];\n      var store_propagation = [];\n      var varID = optimized.memory || 0;\n      var neurons = optimized.neurons || 1;\n      var inputs = optimized.inputs || [];\n      var targets = optimized.targets || [];\n      var outputs = optimized.outputs || [];\n      var variables = optimized.variables || {};\n      var activation_sentences = optimized.activation_sentences || [];\n      var trace_sentences = optimized.trace_sentences || [];\n      var propagation_sentences = optimized.propagation_sentences || [];\n      var layers = optimized.layers || { __count: 0, __neuron: 0 };\n\n      // allocate sentences\n      var allocate = function allocate(store) {\n        var allocated = layer in layers && store[layers.__count];\n        if (!allocated) {\n          layers.__count = store.push([]) - 1;\n          layers[layer] = layers.__count;\n        }\n      };\n      allocate(activation_sentences);\n      allocate(trace_sentences);\n      allocate(propagation_sentences);\n      var currentLayer = layers.__count;\n\n      // get/reserve space in memory by creating a unique ID for a variablel\n      var getVar = function getVar() {\n        var args = Array.prototype.slice.call(arguments);\n\n        if (args.length == 1) {\n          if (args[0] == 'target') {\n            var id = 'target_' + targets.length;\n            targets.push(varID);\n          } else var id = args[0];\n          if (id in variables) return variables[id];\n          return variables[id] = {\n            value: 0,\n            id: varID++\n          };\n        } else {\n          var extended = args.length > 2;\n          if (extended) var value = args.pop();\n\n          var unit = args.shift();\n          var prop = args.pop();\n\n          if (!extended) var value = unit[prop];\n\n          var id = prop + '_';\n          for (var i = 0; i < args.length; i++) {\n            id += args[i] + '_';\n          }id += unit.ID;\n          if (id in variables) return variables[id];\n\n          return variables[id] = {\n            value: value,\n            id: varID++\n          };\n        }\n      };\n\n      // build sentence\n      var buildSentence = function buildSentence() {\n        var args = Array.prototype.slice.call(arguments);\n        var store = args.pop();\n        var sentence = '';\n        for (var i = 0; i < args.length; i++) {\n          if (typeof args[i] == 'string') sentence += args[i];else sentence += 'F[' + args[i].id + ']';\n        }store.push(sentence + ';');\n      };\n\n      // helper to check if an object is empty\n      var isEmpty = function isEmpty(obj) {\n        for (var prop in obj) {\n          if (obj.hasOwnProperty(prop)) return false;\n        }\n        return true;\n      };\n\n      // characteristics of the neuron\n      var noProjections = isEmpty(this.connections.projected);\n      var noGates = isEmpty(this.connections.gated);\n      var isInput = layer == 'input' ? true : isEmpty(this.connections.inputs);\n      var isOutput = layer == 'output' ? true : noProjections && noGates;\n\n      // optimize neuron's behaviour\n      var rate = getVar('rate');\n      var activation = getVar(this, 'activation');\n      if (isInput) inputs.push(activation.id);else {\n        activation_sentences[currentLayer].push(store_activation);\n        trace_sentences[currentLayer].push(store_trace);\n        propagation_sentences[currentLayer].push(store_propagation);\n        var old = getVar(this, 'old');\n        var state = getVar(this, 'state');\n        var bias = getVar(this, 'bias');\n        if (this.selfconnection.gater) var self_gain = getVar(this.selfconnection, 'gain');\n        if (this.selfconnected()) var self_weight = getVar(this.selfconnection, 'weight');\n        buildSentence(old, ' = ', state, store_activation);\n        if (this.selfconnected()) {\n          if (this.selfconnection.gater) buildSentence(state, ' = ', self_gain, ' * ', self_weight, ' * ', state, ' + ', bias, store_activation);else buildSentence(state, ' = ', self_weight, ' * ', state, ' + ', bias, store_activation);\n        } else buildSentence(state, ' = ', bias, store_activation);\n        for (var i in this.connections.inputs) {\n          var input = this.connections.inputs[i];\n          var input_activation = getVar(input.from, 'activation');\n          var input_weight = getVar(input, 'weight');\n          if (input.gater) var input_gain = getVar(input, 'gain');\n          if (this.connections.inputs[i].gater) buildSentence(state, ' += ', input_activation, ' * ', input_weight, ' * ', input_gain, store_activation);else buildSentence(state, ' += ', input_activation, ' * ', input_weight, store_activation);\n        }\n        var derivative = getVar(this, 'derivative');\n        switch (this.squash) {\n          case Neuron.squash.LOGISTIC:\n            buildSentence(activation, ' = (1 / (1 + Math.exp(-', state, ')))', store_activation);\n            buildSentence(derivative, ' = ', activation, ' * (1 - ', activation, ')', store_activation);\n            break;\n          case Neuron.squash.TANH:\n            var eP = getVar('aux');\n            var eN = getVar('aux_2');\n            buildSentence(eP, ' = Math.exp(', state, ')', store_activation);\n            buildSentence(eN, ' = 1 / ', eP, store_activation);\n            buildSentence(activation, ' = (', eP, ' - ', eN, ') / (', eP, ' + ', eN, ')', store_activation);\n            buildSentence(derivative, ' = 1 - (', activation, ' * ', activation, ')', store_activation);\n            break;\n          case Neuron.squash.IDENTITY:\n            buildSentence(activation, ' = ', state, store_activation);\n            buildSentence(derivative, ' = 1', store_activation);\n            break;\n          case Neuron.squash.HLIM:\n            buildSentence(activation, ' = +(', state, ' > 0)', store_activation);\n            buildSentence(derivative, ' = 1', store_activation);\n            break;\n          case Neuron.squash.RELU:\n            buildSentence(activation, ' = ', state, ' > 0 ? ', state, ' : 0', store_activation);\n            buildSentence(derivative, ' = ', state, ' > 0 ? 1 : 0', store_activation);\n            break;\n        }\n\n        for (var id in this.trace.extended) {\n          // calculate extended elegibility traces in advance\n          var neuron = this.neighboors[id];\n          var influence = getVar('influences[' + neuron.ID + ']');\n          var neuron_old = getVar(neuron, 'old');\n          var initialized = false;\n          if (neuron.selfconnection.gater == this) {\n            buildSentence(influence, ' = ', neuron_old, store_trace);\n            initialized = true;\n          }\n          for (var incoming in this.trace.influences[neuron.ID]) {\n            var incoming_weight = getVar(this.trace.influences[neuron.ID][incoming], 'weight');\n            var incoming_activation = getVar(this.trace.influences[neuron.ID][incoming].from, 'activation');\n\n            if (initialized) buildSentence(influence, ' += ', incoming_weight, ' * ', incoming_activation, store_trace);else {\n              buildSentence(influence, ' = ', incoming_weight, ' * ', incoming_activation, store_trace);\n              initialized = true;\n            }\n          }\n        }\n\n        for (var i in this.connections.inputs) {\n          var input = this.connections.inputs[i];\n          if (input.gater) var input_gain = getVar(input, 'gain');\n          var input_activation = getVar(input.from, 'activation');\n          var trace = getVar(this, 'trace', 'elegibility', input.ID, this.trace.elegibility[input.ID]);\n          if (this.selfconnected()) {\n            if (this.selfconnection.gater) {\n              if (input.gater) buildSentence(trace, ' = ', self_gain, ' * ', self_weight, ' * ', trace, ' + ', input_gain, ' * ', input_activation, store_trace);else buildSentence(trace, ' = ', self_gain, ' * ', self_weight, ' * ', trace, ' + ', input_activation, store_trace);\n            } else {\n              if (input.gater) buildSentence(trace, ' = ', self_weight, ' * ', trace, ' + ', input_gain, ' * ', input_activation, store_trace);else buildSentence(trace, ' = ', self_weight, ' * ', trace, ' + ', input_activation, store_trace);\n            }\n          } else {\n            if (input.gater) buildSentence(trace, ' = ', input_gain, ' * ', input_activation, store_trace);else buildSentence(trace, ' = ', input_activation, store_trace);\n          }\n          for (var id in this.trace.extended) {\n            // extended elegibility trace\n            var neuron = this.neighboors[id];\n            var influence = getVar('influences[' + neuron.ID + ']');\n\n            var trace = getVar(this, 'trace', 'elegibility', input.ID, this.trace.elegibility[input.ID]);\n            var xtrace = getVar(this, 'trace', 'extended', neuron.ID, input.ID, this.trace.extended[neuron.ID][input.ID]);\n            if (neuron.selfconnected()) var neuron_self_weight = getVar(neuron.selfconnection, 'weight');\n            if (neuron.selfconnection.gater) var neuron_self_gain = getVar(neuron.selfconnection, 'gain');\n            if (neuron.selfconnected()) {\n              if (neuron.selfconnection.gater) buildSentence(xtrace, ' = ', neuron_self_gain, ' * ', neuron_self_weight, ' * ', xtrace, ' + ', derivative, ' * ', trace, ' * ', influence, store_trace);else buildSentence(xtrace, ' = ', neuron_self_weight, ' * ', xtrace, ' + ', derivative, ' * ', trace, ' * ', influence, store_trace);\n            } else buildSentence(xtrace, ' = ', derivative, ' * ', trace, ' * ', influence, store_trace);\n          }\n        }\n        for (var connection in this.connections.gated) {\n          var gated_gain = getVar(this.connections.gated[connection], 'gain');\n          buildSentence(gated_gain, ' = ', activation, store_activation);\n        }\n      }\n      if (!isInput) {\n        var responsibility = getVar(this, 'error', 'responsibility', this.error.responsibility);\n        if (isOutput) {\n          var target = getVar('target');\n          buildSentence(responsibility, ' = ', target, ' - ', activation, store_propagation);\n          for (var id in this.connections.inputs) {\n            var input = this.connections.inputs[id];\n            var trace = getVar(this, 'trace', 'elegibility', input.ID, this.trace.elegibility[input.ID]);\n            var input_weight = getVar(input, 'weight');\n            buildSentence(input_weight, ' += ', rate, ' * (', responsibility, ' * ', trace, ')', store_propagation);\n          }\n          outputs.push(activation.id);\n        } else {\n          if (!noProjections && !noGates) {\n            var error = getVar('aux');\n            for (var id in this.connections.projected) {\n              var connection = this.connections.projected[id];\n              var neuron = connection.to;\n              var connection_weight = getVar(connection, 'weight');\n              var neuron_responsibility = getVar(neuron, 'error', 'responsibility', neuron.error.responsibility);\n              if (connection.gater) {\n                var connection_gain = getVar(connection, 'gain');\n                buildSentence(error, ' += ', neuron_responsibility, ' * ', connection_gain, ' * ', connection_weight, store_propagation);\n              } else buildSentence(error, ' += ', neuron_responsibility, ' * ', connection_weight, store_propagation);\n            }\n            var projected = getVar(this, 'error', 'projected', this.error.projected);\n            buildSentence(projected, ' = ', derivative, ' * ', error, store_propagation);\n            buildSentence(error, ' = 0', store_propagation);\n            for (var id in this.trace.extended) {\n              var neuron = this.neighboors[id];\n              var influence = getVar('aux_2');\n              var neuron_old = getVar(neuron, 'old');\n              if (neuron.selfconnection.gater == this) buildSentence(influence, ' = ', neuron_old, store_propagation);else buildSentence(influence, ' = 0', store_propagation);\n              for (var input in this.trace.influences[neuron.ID]) {\n                var connection = this.trace.influences[neuron.ID][input];\n                var connection_weight = getVar(connection, 'weight');\n                var neuron_activation = getVar(connection.from, 'activation');\n                buildSentence(influence, ' += ', connection_weight, ' * ', neuron_activation, store_propagation);\n              }\n              var neuron_responsibility = getVar(neuron, 'error', 'responsibility', neuron.error.responsibility);\n              buildSentence(error, ' += ', neuron_responsibility, ' * ', influence, store_propagation);\n            }\n            var gated = getVar(this, 'error', 'gated', this.error.gated);\n            buildSentence(gated, ' = ', derivative, ' * ', error, store_propagation);\n            buildSentence(responsibility, ' = ', projected, ' + ', gated, store_propagation);\n            for (var id in this.connections.inputs) {\n              var input = this.connections.inputs[id];\n              var gradient = getVar('aux');\n              var trace = getVar(this, 'trace', 'elegibility', input.ID, this.trace.elegibility[input.ID]);\n              buildSentence(gradient, ' = ', projected, ' * ', trace, store_propagation);\n              for (var id in this.trace.extended) {\n                var neuron = this.neighboors[id];\n                var neuron_responsibility = getVar(neuron, 'error', 'responsibility', neuron.error.responsibility);\n                var xtrace = getVar(this, 'trace', 'extended', neuron.ID, input.ID, this.trace.extended[neuron.ID][input.ID]);\n                buildSentence(gradient, ' += ', neuron_responsibility, ' * ', xtrace, store_propagation);\n              }\n              var input_weight = getVar(input, 'weight');\n              buildSentence(input_weight, ' += ', rate, ' * ', gradient, store_propagation);\n            }\n          } else if (noGates) {\n            buildSentence(responsibility, ' = 0', store_propagation);\n            for (var id in this.connections.projected) {\n              var connection = this.connections.projected[id];\n              var neuron = connection.to;\n              var connection_weight = getVar(connection, 'weight');\n              var neuron_responsibility = getVar(neuron, 'error', 'responsibility', neuron.error.responsibility);\n              if (connection.gater) {\n                var connection_gain = getVar(connection, 'gain');\n                buildSentence(responsibility, ' += ', neuron_responsibility, ' * ', connection_gain, ' * ', connection_weight, store_propagation);\n              } else buildSentence(responsibility, ' += ', neuron_responsibility, ' * ', connection_weight, store_propagation);\n            }\n            buildSentence(responsibility, ' *= ', derivative, store_propagation);\n            for (var id in this.connections.inputs) {\n              var input = this.connections.inputs[id];\n              var trace = getVar(this, 'trace', 'elegibility', input.ID, this.trace.elegibility[input.ID]);\n              var input_weight = getVar(input, 'weight');\n              buildSentence(input_weight, ' += ', rate, ' * (', responsibility, ' * ', trace, ')', store_propagation);\n            }\n          } else if (noProjections) {\n            buildSentence(responsibility, ' = 0', store_propagation);\n            for (var id in this.trace.extended) {\n              var neuron = this.neighboors[id];\n              var influence = getVar('aux');\n              var neuron_old = getVar(neuron, 'old');\n              if (neuron.selfconnection.gater == this) buildSentence(influence, ' = ', neuron_old, store_propagation);else buildSentence(influence, ' = 0', store_propagation);\n              for (var input in this.trace.influences[neuron.ID]) {\n                var connection = this.trace.influences[neuron.ID][input];\n                var connection_weight = getVar(connection, 'weight');\n                var neuron_activation = getVar(connection.from, 'activation');\n                buildSentence(influence, ' += ', connection_weight, ' * ', neuron_activation, store_propagation);\n              }\n              var neuron_responsibility = getVar(neuron, 'error', 'responsibility', neuron.error.responsibility);\n              buildSentence(responsibility, ' += ', neuron_responsibility, ' * ', influence, store_propagation);\n            }\n            buildSentence(responsibility, ' *= ', derivative, store_propagation);\n            for (var id in this.connections.inputs) {\n              var input = this.connections.inputs[id];\n              var gradient = getVar('aux');\n              buildSentence(gradient, ' = 0', store_propagation);\n              for (var id in this.trace.extended) {\n                var neuron = this.neighboors[id];\n                var neuron_responsibility = getVar(neuron, 'error', 'responsibility', neuron.error.responsibility);\n                var xtrace = getVar(this, 'trace', 'extended', neuron.ID, input.ID, this.trace.extended[neuron.ID][input.ID]);\n                buildSentence(gradient, ' += ', neuron_responsibility, ' * ', xtrace, store_propagation);\n              }\n              var input_weight = getVar(input, 'weight');\n              buildSentence(input_weight, ' += ', rate, ' * ', gradient, store_propagation);\n            }\n          }\n        }\n        buildSentence(bias, ' += ', rate, ' * ', responsibility, store_propagation);\n      }\n      return {\n        memory: varID,\n        neurons: neurons + 1,\n        inputs: inputs,\n        outputs: outputs,\n        targets: targets,\n        variables: variables,\n        activation_sentences: activation_sentences,\n        trace_sentences: trace_sentences,\n        propagation_sentences: propagation_sentences,\n        layers: layers\n      };\n    }\n  }], [{\n    key: 'uid',\n    value: function uid() {\n      return neurons++;\n    }\n  }, {\n    key: 'quantity',\n    value: function quantity() {\n      return {\n        neurons: neurons,\n        connections: _Connection.connections\n      };\n    }\n  }]);\n\n  return Neuron;\n}();\n\nNeuron.squash = squash;\nexports.default = Neuron;\n\n/***/ }),\n/* 3 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n//+ Jonas Raoni Soares Silva\n//@ http://jsfromhell.com/array/shuffle [v1.0]\nfunction shuffleInplace(o) {\n  //v1.0\n  for (var j, x, i = o.length; i; j = Math.floor(Math.random() * i), x = o[--i], o[i] = o[j], o[j] = x) {}\n  return o;\n};\n\n// Built-in cost functions\nvar cost = {\n  // Eq. 9\n  CROSS_ENTROPY: function CROSS_ENTROPY(target, output) {\n    var crossentropy = 0;\n    for (var i in output) {\n      crossentropy -= target[i] * Math.log(output[i] + 1e-15) + (1 - target[i]) * Math.log(1 + 1e-15 - output[i]);\n    } // +1e-15 is a tiny push away to avoid Math.log(0)\n    return crossentropy;\n  },\n  MSE: function MSE(target, output) {\n    var mse = 0;\n    for (var i = 0; i < output.length; i++) {\n      mse += Math.pow(target[i] - output[i], 2);\n    }return mse / output.length;\n  },\n  BINARY: function BINARY(target, output) {\n    var misses = 0;\n    for (var i = 0; i < output.length; i++) {\n      misses += Math.round(target[i] * 2) != Math.round(output[i] * 2);\n    }return misses;\n  }\n};\n\nvar Trainer = function () {\n  function Trainer(network, options) {\n    _classCallCheck(this, Trainer);\n\n    options = options || {};\n    this.network = network;\n    this.rate = options.rate || .2;\n    this.iterations = options.iterations || 100000;\n    this.error = options.error || .005;\n    this.cost = options.cost || null;\n    this.crossValidate = options.crossValidate || null;\n  }\n\n  // trains any given set to a network\n\n\n  _createClass(Trainer, [{\n    key: 'train',\n    value: function train(set, options) {\n      var error = 1;\n      var iterations = bucketSize = 0;\n      var abort = false;\n      var currentRate;\n      var cost = options && options.cost || this.cost || Trainer.cost.MSE;\n      var crossValidate = false,\n          testSet,\n          trainSet;\n\n      var start = Date.now();\n\n      if (options) {\n        if (options.iterations) this.iterations = options.iterations;\n        if (options.error) this.error = options.error;\n        if (options.rate) this.rate = options.rate;\n        if (options.cost) this.cost = options.cost;\n        if (options.schedule) this.schedule = options.schedule;\n        if (options.customLog) {\n          // for backward compatibility with code that used customLog\n          console.log('Deprecated: use schedule instead of customLog');\n          this.schedule = options.customLog;\n        }\n        if (this.crossValidate || options.crossValidate) {\n          if (!this.crossValidate) this.crossValidate = {};\n          crossValidate = true;\n          if (options.crossValidate.testSize) this.crossValidate.testSize = options.crossValidate.testSize;\n          if (options.crossValidate.testError) this.crossValidate.testError = options.crossValidate.testError;\n        }\n      }\n\n      currentRate = this.rate;\n      if (Array.isArray(this.rate)) {\n        var bucketSize = Math.floor(this.iterations / this.rate.length);\n      }\n\n      if (crossValidate) {\n        var numTrain = Math.ceil((1 - this.crossValidate.testSize) * set.length);\n        trainSet = set.slice(0, numTrain);\n        testSet = set.slice(numTrain);\n      }\n\n      var lastError = 0;\n      while (!abort && iterations < this.iterations && error > this.error) {\n        if (crossValidate && error <= this.crossValidate.testError) {\n          break;\n        }\n\n        var currentSetSize = set.length;\n        error = 0;\n        iterations++;\n\n        if (bucketSize > 0) {\n          var currentBucket = Math.floor(iterations / bucketSize);\n          currentRate = this.rate[currentBucket] || currentRate;\n        }\n\n        if (typeof this.rate === 'function') {\n          currentRate = this.rate(iterations, lastError);\n        }\n\n        if (crossValidate) {\n          this._trainSet(trainSet, currentRate, cost);\n          error += this.test(testSet).error;\n          currentSetSize = 1;\n        } else {\n          error += this._trainSet(set, currentRate, cost);\n          currentSetSize = set.length;\n        }\n\n        // check error\n        error /= currentSetSize;\n        lastError = error;\n\n        if (options) {\n          if (this.schedule && this.schedule.every && iterations % this.schedule.every == 0) abort = this.schedule.do({ error: error, iterations: iterations, rate: currentRate });else if (options.log && iterations % options.log == 0) {\n            console.log('iterations', iterations, 'error', error, 'rate', currentRate);\n          }\n          ;\n          if (options.shuffle) shuffleInplace(set);\n        }\n      }\n\n      var results = {\n        error: error,\n        iterations: iterations,\n        time: Date.now() - start\n      };\n\n      return results;\n    }\n\n    // trains any given set to a network, using a WebWorker (only for the browser). Returns a Promise of the results.\n\n  }, {\n    key: 'trainAsync',\n    value: function trainAsync(set, options) {\n      var train = this.workerTrain.bind(this);\n      return new Promise(function (resolve, reject) {\n        try {\n          train(set, resolve, options, true);\n        } catch (e) {\n          reject(e);\n        }\n      });\n    }\n\n    // preforms one training epoch and returns the error (private function used in this.train)\n\n  }, {\n    key: '_trainSet',\n    value: function _trainSet(set, currentRate, costFunction) {\n      var errorSum = 0;\n      for (var i = 0; i < set.length; i++) {\n        var input = set[i].input;\n        var target = set[i].output;\n\n        var output = this.network.activate(input);\n        this.network.propagate(currentRate, target);\n\n        errorSum += costFunction(target, output);\n      }\n      return errorSum;\n    }\n\n    // tests a set and returns the error and elapsed time\n\n  }, {\n    key: 'test',\n    value: function test(set, options) {\n      var error = 0;\n      var input, output, target;\n      var cost = options && options.cost || this.cost || Trainer.cost.MSE;\n\n      var start = Date.now();\n\n      for (var i = 0; i < set.length; i++) {\n        input = set[i].input;\n        target = set[i].output;\n        output = this.network.activate(input);\n        error += cost(target, output);\n      }\n\n      error /= set.length;\n\n      var results = {\n        error: error,\n        time: Date.now() - start\n      };\n\n      return results;\n    }\n\n    // trains any given set to a network using a WebWorker [deprecated: use trainAsync instead]\n\n  }, {\n    key: 'workerTrain',\n    value: function workerTrain(set, callback, options, suppressWarning) {\n      if (!suppressWarning) {\n        console.warn('Deprecated: do not use `workerTrain`, use `trainAsync` instead.');\n      }\n      var that = this;\n\n      if (!this.network.optimized) this.network.optimize();\n\n      // Create a new worker\n      var worker = this.network.worker(this.network.optimized.memory, set, options);\n\n      // train the worker\n      worker.onmessage = function (e) {\n        switch (e.data.action) {\n          case 'done':\n            var iterations = e.data.message.iterations;\n            var error = e.data.message.error;\n            var time = e.data.message.time;\n\n            that.network.optimized.ownership(e.data.memoryBuffer);\n\n            // Done callback\n            callback({\n              error: error,\n              iterations: iterations,\n              time: time\n            });\n\n            // Delete the worker and all its associated memory\n            worker.terminate();\n            break;\n\n          case 'log':\n            console.log(e.data.message);\n\n          case 'schedule':\n            if (options && options.schedule && typeof options.schedule.do === 'function') {\n              var scheduled = options.schedule.do;\n              scheduled(e.data.message);\n            }\n            break;\n        }\n      };\n\n      // Start the worker\n      worker.postMessage({ action: 'startTraining' });\n    }\n\n    // trains an XOR to the network\n\n  }, {\n    key: 'XOR',\n    value: function XOR(options) {\n      if (this.network.inputs() != 2 || this.network.outputs() != 1) throw new Error('Incompatible network (2 inputs, 1 output)');\n\n      var defaults = {\n        iterations: 100000,\n        log: false,\n        shuffle: true,\n        cost: Trainer.cost.MSE\n      };\n\n      if (options) for (var i in options) {\n        defaults[i] = options[i];\n      }return this.train([{\n        input: [0, 0],\n        output: [0]\n      }, {\n        input: [1, 0],\n        output: [1]\n      }, {\n        input: [0, 1],\n        output: [1]\n      }, {\n        input: [1, 1],\n        output: [0]\n      }], defaults);\n    }\n\n    // trains the network to pass a Distracted Sequence Recall test\n\n  }, {\n    key: 'DSR',\n    value: function DSR(options) {\n      options = options || {};\n\n      var targets = options.targets || [2, 4, 7, 8];\n      var distractors = options.distractors || [3, 5, 6, 9];\n      var prompts = options.prompts || [0, 1];\n      var length = options.length || 24;\n      var criterion = options.success || 0.95;\n      var iterations = options.iterations || 100000;\n      var rate = options.rate || .1;\n      var log = options.log || 0;\n      var schedule = options.schedule || {};\n      var cost = options.cost || this.cost || Trainer.cost.CROSS_ENTROPY;\n\n      var trial, correct, i, j, success;\n      trial = correct = i = j = success = 0;\n      var error = 1,\n          symbols = targets.length + distractors.length + prompts.length;\n\n      var noRepeat = function noRepeat(range, avoid) {\n        var number = Math.random() * range | 0;\n        var used = false;\n        for (var i in avoid) {\n          if (number == avoid[i]) used = true;\n        }return used ? noRepeat(range, avoid) : number;\n      };\n\n      var equal = function equal(prediction, output) {\n        for (var i in prediction) {\n          if (Math.round(prediction[i]) != output[i]) return false;\n        }return true;\n      };\n\n      var start = Date.now();\n\n      while (trial < iterations && (success < criterion || trial % 1000 != 0)) {\n        // generate sequence\n        var sequence = [],\n            sequenceLength = length - prompts.length;\n        for (i = 0; i < sequenceLength; i++) {\n          var any = Math.random() * distractors.length | 0;\n          sequence.push(distractors[any]);\n        }\n        var indexes = [],\n            positions = [];\n        for (i = 0; i < prompts.length; i++) {\n          indexes.push(Math.random() * targets.length | 0);\n          positions.push(noRepeat(sequenceLength, positions));\n        }\n        positions = positions.sort();\n        for (i = 0; i < prompts.length; i++) {\n          sequence[positions[i]] = targets[indexes[i]];\n          sequence.push(prompts[i]);\n        }\n\n        //train sequence\n        var distractorsCorrect;\n        var targetsCorrect = distractorsCorrect = 0;\n        error = 0;\n        for (i = 0; i < length; i++) {\n          // generate input from sequence\n          var input = [];\n          for (j = 0; j < symbols; j++) {\n            input[j] = 0;\n          }input[sequence[i]] = 1;\n\n          // generate target output\n          var output = [];\n          for (j = 0; j < targets.length; j++) {\n            output[j] = 0;\n          }if (i >= sequenceLength) {\n            var index = i - sequenceLength;\n            output[indexes[index]] = 1;\n          }\n\n          // check result\n          var prediction = this.network.activate(input);\n\n          if (equal(prediction, output)) {\n            if (i < sequenceLength) distractorsCorrect++;else targetsCorrect++;\n          } else {\n            this.network.propagate(rate, output);\n          }\n\n          error += cost(output, prediction);\n\n          if (distractorsCorrect + targetsCorrect == length) correct++;\n        }\n\n        // calculate error\n        if (trial % 1000 == 0) correct = 0;\n        trial++;\n        var divideError = trial % 1000;\n        divideError = divideError == 0 ? 1000 : divideError;\n        success = correct / divideError;\n        error /= length;\n\n        // log\n        if (log && trial % log == 0) console.log('iterations:', trial, ' success:', success, ' correct:', correct, ' time:', Date.now() - start, ' error:', error);\n        if (schedule.do && schedule.every && trial % schedule.every == 0) schedule.do({\n          iterations: trial,\n          success: success,\n          error: error,\n          time: Date.now() - start,\n          correct: correct\n        });\n      }\n\n      return {\n        iterations: trial,\n        success: success,\n        error: error,\n        time: Date.now() - start\n      };\n    }\n\n    // train the network to learn an Embeded Reber Grammar\n\n  }, {\n    key: 'ERG',\n    value: function ERG(options) {\n\n      options = options || {};\n      var iterations = options.iterations || 150000;\n      var criterion = options.error || .05;\n      var rate = options.rate || .1;\n      var log = options.log || 500;\n      var cost = options.cost || this.cost || Trainer.cost.CROSS_ENTROPY;\n\n      // gramar node\n      var Node = function Node() {\n        this.paths = [];\n      };\n      Node.prototype = {\n        connect: function connect(node, value) {\n          this.paths.push({\n            node: node,\n            value: value\n          });\n          return this;\n        },\n        any: function any() {\n          if (this.paths.length == 0) return false;\n          var index = Math.random() * this.paths.length | 0;\n          return this.paths[index];\n        },\n        test: function test(value) {\n          for (var i in this.paths) {\n            if (this.paths[i].value == value) return this.paths[i];\n          }return false;\n        }\n      };\n\n      var reberGrammar = function reberGrammar() {\n\n        // build a reber grammar\n        var output = new Node();\n        var n1 = new Node().connect(output, 'E');\n        var n2 = new Node().connect(n1, 'S');\n        var n3 = new Node().connect(n1, 'V').connect(n2, 'P');\n        var n4 = new Node().connect(n2, 'X');\n        n4.connect(n4, 'S');\n        var n5 = new Node().connect(n3, 'V');\n        n5.connect(n5, 'T');\n        n2.connect(n5, 'X');\n        var n6 = new Node().connect(n4, 'T').connect(n5, 'P');\n        var input = new Node().connect(n6, 'B');\n\n        return {\n          input: input,\n          output: output\n        };\n      };\n\n      // build an embeded reber grammar\n      var embededReberGrammar = function embededReberGrammar() {\n        var reber1 = reberGrammar();\n        var reber2 = reberGrammar();\n\n        var output = new Node();\n        var n1 = new Node().connect(output, 'E');\n        reber1.output.connect(n1, 'T');\n        reber2.output.connect(n1, 'P');\n        var n2 = new Node().connect(reber1.input, 'P').connect(reber2.input, 'T');\n        var input = new Node().connect(n2, 'B');\n\n        return {\n          input: input,\n          output: output\n        };\n      };\n\n      // generate an ERG sequence\n      var generate = function generate() {\n        var node = embededReberGrammar().input;\n        var next = node.any();\n        var str = '';\n        while (next) {\n          str += next.value;\n          next = next.node.any();\n        }\n        return str;\n      };\n\n      // test if a string matches an embeded reber grammar\n      var test = function test(str) {\n        var node = embededReberGrammar().input;\n        var i = 0;\n        var ch = str.charAt(i);\n        while (i < str.length) {\n          var next = node.test(ch);\n          if (!next) return false;\n          node = next.node;\n          ch = str.charAt(++i);\n        }\n        return true;\n      };\n\n      // helper to check if the output and the target vectors match\n      var different = function different(array1, array2) {\n        var max1 = 0;\n        var i1 = -1;\n        var max2 = 0;\n        var i2 = -1;\n        for (var i in array1) {\n          if (array1[i] > max1) {\n            max1 = array1[i];\n            i1 = i;\n          }\n          if (array2[i] > max2) {\n            max2 = array2[i];\n            i2 = i;\n          }\n        }\n\n        return i1 != i2;\n      };\n\n      var iteration = 0;\n      var error = 1;\n      var table = {\n        'B': 0,\n        'P': 1,\n        'T': 2,\n        'X': 3,\n        'S': 4,\n        'E': 5\n      };\n\n      var start = Date.now();\n      while (iteration < iterations && error > criterion) {\n        var i = 0;\n        error = 0;\n\n        // ERG sequence to learn\n        var sequence = generate();\n\n        // input\n        var read = sequence.charAt(i);\n        // target\n        var predict = sequence.charAt(i + 1);\n\n        // train\n        while (i < sequence.length - 1) {\n          var input = [];\n          var target = [];\n          for (var j = 0; j < 6; j++) {\n            input[j] = 0;\n            target[j] = 0;\n          }\n          input[table[read]] = 1;\n          target[table[predict]] = 1;\n\n          var output = this.network.activate(input);\n\n          if (different(output, target)) this.network.propagate(rate, target);\n\n          read = sequence.charAt(++i);\n          predict = sequence.charAt(i + 1);\n\n          error += cost(target, output);\n        }\n        error /= sequence.length;\n        iteration++;\n        if (iteration % log == 0) {\n          console.log('iterations:', iteration, ' time:', Date.now() - start, ' error:', error);\n        }\n      }\n\n      return {\n        iterations: iteration,\n        error: error,\n        time: Date.now() - start,\n        test: test,\n        generate: generate\n      };\n    }\n  }, {\n    key: 'timingTask',\n    value: function timingTask(options) {\n\n      if (this.network.inputs() != 2 || this.network.outputs() != 1) throw new Error('Invalid Network: must have 2 inputs and one output');\n\n      if (typeof options == 'undefined') options = {};\n\n      // helper\n      function getSamples(trainingSize, testSize) {\n\n        // sample size\n        var size = trainingSize + testSize;\n\n        // generate samples\n        var t = 0;\n        var set = [];\n        for (var i = 0; i < size; i++) {\n          set.push({ input: [0, 0], output: [0] });\n        }\n        while (t < size - 20) {\n          var n = Math.round(Math.random() * 20);\n          set[t].input[0] = 1;\n          for (var j = t; j <= t + n; j++) {\n            set[j].input[1] = n / 20;\n            set[j].output[0] = 0.5;\n          }\n          t += n;\n          n = Math.round(Math.random() * 20);\n          for (var k = t + 1; k <= t + n && k < size; k++) {\n            set[k].input[1] = set[t].input[1];\n          }t += n;\n        }\n\n        // separate samples between train and test sets\n        var trainingSet = [];\n        var testSet = [];\n        for (var l = 0; l < size; l++) {\n          (l < trainingSize ? trainingSet : testSet).push(set[l]);\n        } // return samples\n        return {\n          train: trainingSet,\n          test: testSet\n        };\n      }\n\n      var iterations = options.iterations || 200;\n      var error = options.error || .005;\n      var rate = options.rate || [.03, .02];\n      var log = options.log === false ? false : options.log || 10;\n      var cost = options.cost || this.cost || Trainer.cost.MSE;\n      var trainingSamples = options.trainSamples || 7000;\n      var testSamples = options.trainSamples || 1000;\n\n      // samples for training and testing\n      var samples = getSamples(trainingSamples, testSamples);\n\n      // train\n      var result = this.train(samples.train, {\n        rate: rate,\n        log: log,\n        iterations: iterations,\n        error: error,\n        cost: cost\n      });\n\n      return {\n        train: result,\n        test: this.test(samples.test)\n      };\n    }\n  }]);\n\n  return Trainer;\n}();\n\nTrainer.cost = cost;\nexports.default = Trainer;\n\n/***/ }),\n/* 4 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.Architect = exports.Network = exports.Trainer = exports.Layer = exports.Neuron = undefined;\n\nvar _Neuron = __webpack_require__(2);\n\nObject.defineProperty(exports, 'Neuron', {\n  enumerable: true,\n  get: function get() {\n    return _interopRequireDefault(_Neuron).default;\n  }\n});\n\nvar _Layer = __webpack_require__(0);\n\nObject.defineProperty(exports, 'Layer', {\n  enumerable: true,\n  get: function get() {\n    return _interopRequireDefault(_Layer).default;\n  }\n});\n\nvar _Trainer = __webpack_require__(3);\n\nObject.defineProperty(exports, 'Trainer', {\n  enumerable: true,\n  get: function get() {\n    return _interopRequireDefault(_Trainer).default;\n  }\n});\n\nvar _Network = __webpack_require__(1);\n\nObject.defineProperty(exports, 'Network', {\n  enumerable: true,\n  get: function get() {\n    return _interopRequireDefault(_Network).default;\n  }\n});\n\nvar _architect = __webpack_require__(7);\n\nvar Architect = _interopRequireWildcard(_architect);\n\nfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } else { var newObj = {}; if (obj != null) { for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) newObj[key] = obj[key]; } } newObj.default = obj; return newObj; } }\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nexports.Architect = Architect;\n\n/***/ }),\n/* 5 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar connections = exports.connections = 0;\n\nvar Connection = function () {\n  function Connection(from, to, weight) {\n    _classCallCheck(this, Connection);\n\n    if (!from || !to) throw new Error(\"Connection Error: Invalid neurons\");\n\n    this.ID = Connection.uid();\n    this.from = from;\n    this.to = to;\n    this.weight = typeof weight == 'undefined' ? Math.random() * .2 - .1 : weight;\n    this.gain = 1;\n    this.gater = null;\n  }\n\n  _createClass(Connection, null, [{\n    key: \"uid\",\n    value: function uid() {\n      return exports.connections = connections += 1, connections - 1;\n    }\n  }]);\n\n  return Connection;\n}();\n\nexports.default = Connection;\n\n/***/ }),\n/* 6 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.connections = undefined;\n\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nvar _Layer = __webpack_require__(0);\n\nvar _Layer2 = _interopRequireDefault(_Layer);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n// represents a connection from one layer to another, and keeps track of its weight and gain\nvar connections = exports.connections = 0;\n\nvar LayerConnection = function () {\n  function LayerConnection(fromLayer, toLayer, type, weights) {\n    _classCallCheck(this, LayerConnection);\n\n    this.ID = LayerConnection.uid();\n    this.from = fromLayer;\n    this.to = toLayer;\n    this.selfconnection = toLayer == fromLayer;\n    this.type = type;\n    this.connections = {};\n    this.list = [];\n    this.size = 0;\n    this.gatedfrom = [];\n\n    if (typeof this.type == 'undefined') {\n      if (fromLayer == toLayer) this.type = _Layer2.default.connectionType.ONE_TO_ONE;else this.type = _Layer2.default.connectionType.ALL_TO_ALL;\n    }\n\n    if (this.type == _Layer2.default.connectionType.ALL_TO_ALL || this.type == _Layer2.default.connectionType.ALL_TO_ELSE) {\n      for (var here in this.from.list) {\n        for (var there in this.to.list) {\n          var from = this.from.list[here];\n          var to = this.to.list[there];\n          if (this.type == _Layer2.default.connectionType.ALL_TO_ELSE && from == to) continue;\n          var connection = from.project(to, weights);\n\n          this.connections[connection.ID] = connection;\n          this.size = this.list.push(connection);\n        }\n      }\n    } else if (this.type == _Layer2.default.connectionType.ONE_TO_ONE) {\n\n      for (var neuron in this.from.list) {\n        var from = this.from.list[neuron];\n        var to = this.to.list[neuron];\n        var connection = from.project(to, weights);\n\n        this.connections[connection.ID] = connection;\n        this.size = this.list.push(connection);\n      }\n    }\n\n    fromLayer.connectedTo.push(this);\n  }\n\n  _createClass(LayerConnection, null, [{\n    key: 'uid',\n    value: function uid() {\n      return exports.connections = connections += 1, connections - 1;\n    }\n  }]);\n\n  return LayerConnection;\n}();\n\nexports.default = LayerConnection;\n\n/***/ }),\n/* 7 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _Perceptron = __webpack_require__(8);\n\nObject.defineProperty(exports, 'Perceptron', {\n  enumerable: true,\n  get: function get() {\n    return _interopRequireDefault(_Perceptron).default;\n  }\n});\n\nvar _LSTM = __webpack_require__(9);\n\nObject.defineProperty(exports, 'LSTM', {\n  enumerable: true,\n  get: function get() {\n    return _interopRequireDefault(_LSTM).default;\n  }\n});\n\nvar _Liquid = __webpack_require__(10);\n\nObject.defineProperty(exports, 'Liquid', {\n  enumerable: true,\n  get: function get() {\n    return _interopRequireDefault(_Liquid).default;\n  }\n});\n\nvar _Hopfield = __webpack_require__(11);\n\nObject.defineProperty(exports, 'Hopfield', {\n  enumerable: true,\n  get: function get() {\n    return _interopRequireDefault(_Hopfield).default;\n  }\n});\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/***/ }),\n/* 8 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _Network2 = __webpack_require__(1);\n\nvar _Network3 = _interopRequireDefault(_Network2);\n\nvar _Layer = __webpack_require__(0);\n\nvar _Layer2 = _interopRequireDefault(_Layer);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\nvar Perceptron = function (_Network) {\n  _inherits(Perceptron, _Network);\n\n  function Perceptron() {\n    _classCallCheck(this, Perceptron);\n\n    var _this = _possibleConstructorReturn(this, (Perceptron.__proto__ || Object.getPrototypeOf(Perceptron)).call(this));\n\n    var args = Array.prototype.slice.call(arguments); // convert arguments to Array\n    if (args.length < 3) throw new Error('not enough layers (minimum 3) !!');\n\n    var inputs = args.shift(); // first argument\n    var outputs = args.pop(); // last argument\n    var layers = args; // all the arguments in the middle\n\n    var input = new _Layer2.default(inputs);\n    var hidden = [];\n    var output = new _Layer2.default(outputs);\n\n    var previous = input;\n\n    // generate hidden layers\n    for (var i = 0; i < layers.length; i++) {\n      var size = layers[i];\n      var layer = new _Layer2.default(size);\n      hidden.push(layer);\n      previous.project(layer);\n      previous = layer;\n    }\n    previous.project(output);\n\n    // set layers of the neural network\n    _this.set({\n      input: input,\n      hidden: hidden,\n      output: output\n    });\n    return _this;\n  }\n\n  return Perceptron;\n}(_Network3.default);\n\nexports.default = Perceptron;\n\n/***/ }),\n/* 9 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _Network2 = __webpack_require__(1);\n\nvar _Network3 = _interopRequireDefault(_Network2);\n\nvar _Layer = __webpack_require__(0);\n\nvar _Layer2 = _interopRequireDefault(_Layer);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\nvar LSTM = function (_Network) {\n  _inherits(LSTM, _Network);\n\n  function LSTM() {\n    _classCallCheck(this, LSTM);\n\n    var _this = _possibleConstructorReturn(this, (LSTM.__proto__ || Object.getPrototypeOf(LSTM)).call(this));\n\n    var args = Array.prototype.slice.call(arguments); // convert arguments to array\n    if (args.length < 3) throw new Error(\"not enough layers (minimum 3) !!\");\n\n    var last = args.pop();\n    var option = {\n      peepholes: _Layer2.default.connectionType.ALL_TO_ALL,\n      hiddenToHidden: false,\n      outputToHidden: false,\n      outputToGates: false,\n      inputToOutput: true\n    };\n    if (typeof last != 'number') {\n      var outputs = args.pop();\n      if (last.hasOwnProperty('peepholes')) option.peepholes = last.peepholes;\n      if (last.hasOwnProperty('hiddenToHidden')) option.hiddenToHidden = last.hiddenToHidden;\n      if (last.hasOwnProperty('outputToHidden')) option.outputToHidden = last.outputToHidden;\n      if (last.hasOwnProperty('outputToGates')) option.outputToGates = last.outputToGates;\n      if (last.hasOwnProperty('inputToOutput')) option.inputToOutput = last.inputToOutput;\n    } else {\n      var outputs = last;\n    }\n\n    var inputs = args.shift();\n    var layers = args;\n\n    var inputLayer = new _Layer2.default(inputs);\n    var hiddenLayers = [];\n    var outputLayer = new _Layer2.default(outputs);\n\n    var previous = null;\n\n    // generate layers\n    for (var i = 0; i < layers.length; i++) {\n      // generate memory blocks (memory cell and respective gates)\n      var size = layers[i];\n\n      var inputGate = new _Layer2.default(size).set({\n        bias: 1\n      });\n      var forgetGate = new _Layer2.default(size).set({\n        bias: 1\n      });\n      var memoryCell = new _Layer2.default(size);\n      var outputGate = new _Layer2.default(size).set({\n        bias: 1\n      });\n\n      hiddenLayers.push(inputGate);\n      hiddenLayers.push(forgetGate);\n      hiddenLayers.push(memoryCell);\n      hiddenLayers.push(outputGate);\n\n      // connections from input layer\n      var input = inputLayer.project(memoryCell);\n      inputLayer.project(inputGate);\n      inputLayer.project(forgetGate);\n      inputLayer.project(outputGate);\n\n      // connections from previous memory-block layer to this one\n      if (previous != null) {\n        var cell = previous.project(memoryCell);\n        previous.project(inputGate);\n        previous.project(forgetGate);\n        previous.project(outputGate);\n      }\n\n      // connections from memory cell\n      var output = memoryCell.project(outputLayer);\n\n      // self-connection\n      var self = memoryCell.project(memoryCell);\n\n      // hidden to hidden recurrent connection\n      if (option.hiddenToHidden) memoryCell.project(memoryCell, _Layer2.default.connectionType.ALL_TO_ELSE);\n\n      // out to hidden recurrent connection\n      if (option.outputToHidden) outputLayer.project(memoryCell);\n\n      // out to gates recurrent connection\n      if (option.outputToGates) {\n        outputLayer.project(inputGate);\n        outputLayer.project(outputGate);\n        outputLayer.project(forgetGate);\n      }\n\n      // peepholes\n      memoryCell.project(inputGate, option.peepholes);\n      memoryCell.project(forgetGate, option.peepholes);\n      memoryCell.project(outputGate, option.peepholes);\n\n      // gates\n      inputGate.gate(input, _Layer2.default.gateType.INPUT);\n      forgetGate.gate(self, _Layer2.default.gateType.ONE_TO_ONE);\n      outputGate.gate(output, _Layer2.default.gateType.OUTPUT);\n      if (previous != null) inputGate.gate(cell, _Layer2.default.gateType.INPUT);\n\n      previous = memoryCell;\n    }\n\n    // input to output direct connection\n    if (option.inputToOutput) inputLayer.project(outputLayer);\n\n    // set the layers of the neural network\n    _this.set({\n      input: inputLayer,\n      hidden: hiddenLayers,\n      output: outputLayer\n    });\n    return _this;\n  }\n\n  return LSTM;\n}(_Network3.default);\n\nexports.default = LSTM;\n\n/***/ }),\n/* 10 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _Network2 = __webpack_require__(1);\n\nvar _Network3 = _interopRequireDefault(_Network2);\n\nvar _Layer = __webpack_require__(0);\n\nvar _Layer2 = _interopRequireDefault(_Layer);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\nvar Liquid = function (_Network) {\n  _inherits(Liquid, _Network);\n\n  function Liquid(inputs, hidden, outputs, connections, gates) {\n    _classCallCheck(this, Liquid);\n\n    // create layers\n    var _this = _possibleConstructorReturn(this, (Liquid.__proto__ || Object.getPrototypeOf(Liquid)).call(this));\n\n    var inputLayer = new _Layer2.default(inputs);\n    var hiddenLayer = new _Layer2.default(hidden);\n    var outputLayer = new _Layer2.default(outputs);\n\n    // make connections and gates randomly among the neurons\n    var neurons = hiddenLayer.neurons();\n    var connectionList = [];\n\n    for (var i = 0; i < connections; i++) {\n      // connect two random neurons\n      var from = Math.random() * neurons.length | 0;\n      var to = Math.random() * neurons.length | 0;\n      var connection = neurons[from].project(neurons[to]);\n      connectionList.push(connection);\n    }\n\n    for (var j = 0; j < gates; j++) {\n      // pick a random gater neuron\n      var gater = Math.random() * neurons.length | 0;\n      // pick a random connection to gate\n      var connection = Math.random() * connectionList.length | 0;\n      // let the gater gate the connection\n      neurons[gater].gate(connectionList[connection]);\n    }\n\n    // connect the layers\n    inputLayer.project(hiddenLayer);\n    hiddenLayer.project(outputLayer);\n\n    // set the layers of the network\n    _this.set({\n      input: inputLayer,\n      hidden: [hiddenLayer],\n      output: outputLayer\n    });\n    return _this;\n  }\n\n  return Liquid;\n}(_Network3.default);\n\nexports.default = Liquid;\n\n/***/ }),\n/* 11 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nvar _Network2 = __webpack_require__(1);\n\nvar _Network3 = _interopRequireDefault(_Network2);\n\nvar _Trainer = __webpack_require__(3);\n\nvar _Trainer2 = _interopRequireDefault(_Trainer);\n\nvar _Layer = __webpack_require__(0);\n\nvar _Layer2 = _interopRequireDefault(_Layer);\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\nvar Hopfield = function (_Network) {\n  _inherits(Hopfield, _Network);\n\n  function Hopfield(size) {\n    _classCallCheck(this, Hopfield);\n\n    var _this = _possibleConstructorReturn(this, (Hopfield.__proto__ || Object.getPrototypeOf(Hopfield)).call(this));\n\n    var inputLayer = new _Layer2.default(size);\n    var outputLayer = new _Layer2.default(size);\n\n    inputLayer.project(outputLayer, _Layer2.default.connectionType.ALL_TO_ALL);\n\n    _this.set({\n      input: inputLayer,\n      hidden: [],\n      output: outputLayer\n    });\n\n    _this.trainer = new _Trainer2.default(_this);\n    return _this;\n  }\n\n  _createClass(Hopfield, [{\n    key: 'learn',\n    value: function learn(patterns) {\n      var set = [];\n      for (var p in patterns) {\n        set.push({\n          input: patterns[p],\n          output: patterns[p]\n        });\n      }return this.trainer.train(set, {\n        iterations: 500000,\n        error: .00005,\n        rate: 1\n      });\n    }\n  }, {\n    key: 'feed',\n    value: function feed(pattern) {\n      var output = this.activate(pattern);\n\n      var pattern = [];\n      for (var i in output) {\n        pattern[i] = output[i] > .5 ? 1 : 0;\n      }return pattern;\n    }\n  }]);\n\n  return Hopfield;\n}(_Network3.default);\n\nexports.default = Hopfield;\n\n/***/ })\n/******/ ]);\n});","var synaptic = require('synaptic')\n\nvar createRay = require(\"ray-aabb\")\n\nvar canvas = document.getElementById(\"c\")\nvar ctx = canvas.getContext(\"2d\")\n\nvar layers = [6, 4, 4, 3, 2]\n\nvar mutationRate = 0.25\nvar population = 100\nvar carWidth = 5\nvar carHeight = 9\nvar carSpeed = 50\nvar carTurn = 30 * (Math.PI / 180)\nvar numFood = 30\nvar maxScanDist = 300\n\nclass Chromosome {\n    constructor() {\n        this.network = new synaptic.Architect.Perceptron(...layers)\n    }\n\n    copy() {\n        var c = new Chromosome()\n        c.network = synaptic.Network.fromJSON(this.network.toJSON())\n        return c\n    }\n\n    mutate() {\n        this.mapWeights(w => w + (Math.random()*mutationRate*2 - mutationRate))\n        this.mapBiases(b => b + (Math.random()*mutationRate*2 - mutationRate))\n    }\n\n    mapWeights(fn) {\n        var layers = [this.network.layers.input, ...this.network.layers.hidden, this.network.layers.output]\n        layers.forEach(layer => {\n            layer.list.forEach(neuron => {\n                var proj = neuron.connections.projected\n\n                for (var key in proj) {\n                    if (proj.hasOwnProperty(key)) {\n                        proj[key].weight = Math.min(Math.max(fn(proj[key].weight), 0), 1)\n                    }\n                }\n            })\n        })\n        if (this.network.optimized) this.network.optimized.reset()\n    }\n\n    mapBiases(fn) {\n        var layers = [this.network.layers.input, ...this.network.layers.hidden, this.network.layers.output]\n        layers.forEach(layer => {\n            layer.list.forEach(neuron => {\n                neuron.bias = Math.min(Math.max(fn(neuron.bias), -1), 1)\n            })\n        })\n        if (this.network.optimized) this.network.optimized.reset()\n    }\n\n    evaluate(inputs) {\n        return this.network.activate(inputs)\n    }\n}\n\nclass Population {\n    constructor(size, obstacles) {\n        this.cars = []\n        this.obstacles = obstacles\n        this.foodPositions = []\n        this.time = 0\n\n        for (var i = 0; i < size; i++) {\n            this.cars.push(new Car(\n                Math.random()*150 + canvas.width/2 - 75,\n                Math.random()*150 + canvas.height/2 - 75,\n                Math.random() * 2 * Math.PI,\n                new Chromosome(),\n            ))\n        }\n\n        for (var i = 0; i < numFood; i++) {\n            this.foodPositions.push([Math.random()*800+100, Math.random()*600+100])\n        }\n    }\n\n    render(ctx) {\n        this.obstacles.forEach(o => {\n            var w = o[1][0] - o[0][0]\n            var h = o[1][1] - o[0][1]\n            ctx.fillStyle = \"black\"\n            ctx.fillRect(o[0][0], o[0][1], w, h)\n        })\n\n        this.foodPositions.forEach(o => {\n            ctx.fillStyle = \"red\"\n            ctx.fillRect(o[0] - 2.5, o[1] - 2.5, 5, 5)\n        })\n\n        this.cars.forEach(c => c.render(ctx))\n    }\n\n    update(dt) {\n        this.time += dt\n\n        if (this.cars.every(c => c.dead) || this.time > 120) {\n            this.generation()\n            return\n        }\n\n        this.cars.forEach((function(c, i) {\n            var bounds = c.bounds()\n            if (this.collides(bounds, this.obstacles)) {\n                this.kill(i)\n                return\n            }\n\n            this.foodPositions.forEach((function(pos, i) {\n                var x = pos[0]\n                var y = pos[1]\n\n                if (x > bounds[0][0] && y > bounds[0][1] && x < bounds[1][0] && y < bounds[1][1]) {\n                    c.score++\n                    this.foodPositions.splice(i, 1)\n                    this.foodPositions.push([Math.random()*800+100, Math.random()*600+100])\n                }\n            }).bind(this))\n\n            var inputs = this.networkInputs(i)\n            c.update(dt, inputs)\n        }).bind(this))\n    }\n\n    kill(index) {\n        this.cars[index].dead = true\n    }\n\n    getSortedCars() {\n        return this.cars.sort((a, b) => a.fitness() < b.fitness())\n    }\n\n    generation() {\n        this.time = 0\n        var sorted = this.getSortedCars()\n        var best = sorted.slice(0, sorted.length/2)\n\n        var mutated = []\n        for (var car of best) {\n            car.mutate().forEach(c => {\n                mutated.push(new Car(\n                    Math.random()*150 + canvas.width/2 - 75,\n                    Math.random()*150 + canvas.height/2 - 75,\n                    Math.random() * 2 * Math.PI,\n                    c,\n                ))\n            })\n        }\n        \n        this.cars = mutated\n    }\n\n    raycast(index, angle) {\n        var car = this.cars[index]\n        var pos = car.pos\n        var totalAngle = angle + car.rotation\n        var facing = [Math.cos(totalAngle), Math.sin(totalAngle)]\n        var ray = createRay([pos.x, pos.y], facing)\n\n        var min = Infinity\n        for (var obstacle of this.obstacles) {\n            var normal = [0, 0]\n            var d = ray.intersects(obstacle, normal)\n            if (!d) continue\n            min = Math.min(min, d)\n        }\n\n        return min\n    }\n\n    scan(index) {\n        return [-80, -30, 0, 30, 80]\n            .map(deg => deg * (Math.PI / 180))\n            .map(angle => this.raycast(index, angle))\n            .map(dist => dist > maxScanDist ? 1 : dist / maxScanDist)\n    }\n\n    networkInputs(index) {\n        var car = this.cars[index]\n        var scan = this.scan(index)\n        var dist = Infinity\n        var closest = null\n\n        for (var food of this.foodPositions) {\n            var foodDist = Math.hypot(food[0] - car.pos.x, food[1] - car.pos.y)\n            if (foodDist < dist) {\n                dist = foodDist\n                closest = food\n            }\n        }\n\n        if (closest === null) return [...scan, 0]\n\n        var angle = car.angleTo(...closest)\n\n        return [...scan, angle]\n    }\n\n    collides(bounds, objects) {\n        for (var obj of objects) {\n            if (aabbaabb(bounds, obj)) return true\n        }\n\n        return false\n    }\n}\n\nclass Car {\n    constructor(x, y, rot, chromosome) {\n        this.pos = {x: x, y: y}\n        this.vel = {x: 0, y: 0}\n        this.acc = {x: 0, y: 0}\n        this.rotation = rot\n        this.rotationVel = 0\n        this.rotationAcc = 0\n        this.colour = `rgb(${Math.random()*255}, ${Math.random()*255}, ${Math.random()*255})`\n        this.chromosome = chromosome\n        this.score = 0\n        this.counter = 0\n        this.forwardAmount = 0\n        this.turnAmount = 0\n        this.dead = false\n        this.lifetime = 0\n    }\n\n    fitness() {\n        return this.score * this.lifetime\n    }\n\n    mutate() {\n        var a = this.chromosome.copy()\n        var b = this.chromosome.copy()\n        a.mutate()\n        b.mutate()\n        return [a, b]\n    }\n\n    render(ctx) {\n        ctx.save()\n        ctx.translate(this.pos.x, this.pos.y)\n        ctx.rotate(this.rotation)\n\n        ctx.fillStyle = this.dead ? \"rgba(0, 0, 0, 0.3)\" : this.colour\n        ctx.fillRect(-carWidth/2, -carHeight/2, carWidth, carHeight)\n\n        ctx.restore()\n    }\n\n    update(dt, inputs) {\n        if (this.dead) return\n\n        this.lifetime += dt\n        this.counter++\n\n        if (this.counter >= 20) {\n            var res = this.chromosome.evaluate(inputs)\n            this.forwardAmount = res[0]\n            this.turnAmount = res[1]\n            this.counter = 0\n        }\n\n        this.forward(this.forwardAmount)\n        this.turn(this.turnAmount)\n\n        this.acc.x *= 0.9\n        this.acc.y *= 0.9\n        this.vel.x = (this.vel.x + this.acc.x * dt) * 0.95\n        this.vel.y = (this.vel.y + this.acc.y * dt) * 0.95\n        this.pos.x += this.vel.x * dt\n        this.pos.y += this.vel.y * dt\n\n        this.rotationAcc *= 0.9\n        this.rotationVel = (this.rotationVel + this.rotationAcc * dt) * 0.95\n        this.rotation += this.rotationVel * dt\n        this.rotation %= Math.PI * 2\n    }\n\n    angleTo(x, y) {\n        this.rotation %= Math.PI * 2\n        var angle = Math.atan2(y, x)\n        var diff = angle - this.rotation\n        return normalizeAngle(diff)\n    }\n\n    forward(amount) {\n        var speed = carSpeed * amount\n        this.acc.x += Math.cos(this.rotation - Math.PI/2) * speed\n        this.acc.y += Math.sin(this.rotation - Math.PI/2) * speed\n    }\n\n    turn(amount) {\n        var angle = carTurn * 2 * (amount - 0.5)\n        this.rotationAcc += angle\n    }\n\n    bounds() {\n        var theta = this.rotation\n        var sinTheta = Math.sin(theta)\n        var cosTheta = Math.cos(theta)\n        var x0 = this.pos.x\n        var y0 = this.pos.y\n        var w = carWidth\n        var h = carHeight\n\n        function transform(x, y) {\n            return {\n                x: x0 + (x-x0)*cosTheta - (y-y0)*sinTheta,\n                y: y0 + (x-x0)*sinTheta + (y-y0)*cosTheta,\n            }\n        }\n\n        var corners = [\n            {x: x0-w/2, y: y0-h/2},\n            {x: x0+w/2, y: y0-h/2},\n            {x: x0-w/2, y: y0+h/2},\n            {x: x0+w/2, y: y0+h/2},\n        ]\n\n        var transformed = corners.map(c => transform(c.x, c.y))\n        var min = transformed.reduce((min, c) => {\n            return {\n                x: Math.min(min.x, c.x),\n                y: Math.min(min.y, c.y),\n            }\n        }, {x: Infinity, y: Infinity})\n        var max = transformed.reduce((max, c) => {\n            return {\n                x: Math.max(max.x, c.x),\n                y: Math.max(max.y, c.y),\n            }\n        }, {x: -Infinity, y: -Infinity})\n\n        return [[min.x, min.y], [max.x, max.y]]\n    }\n}\n\nfunction normalizeAngle(rad) {\n    return (rad % (Math.PI*2)) / (Math.PI*2) + 0.5\n}\n\nfunction unnormalizeAngle(n) {\n    return (n - 0.5) * (Math.PI*2)\n}\n\nfunction aabbaabb(a, b) {\n    var aw = Math.abs(a[1][0] - a[0][0])\n    var bw = Math.abs(b[1][0] - b[0][0])\n    var ah = Math.abs(a[1][1] - a[0][1])\n    var bh = Math.abs(b[1][1] - b[0][1])\n    var ac = [a[0][0] + aw/2, a[0][1] + ah/2]\n    var bc = [b[0][0] + bw/2, b[0][1] + bh/2]\n    var ar = [aw/2, ah/2]\n    var br = [bw/2, bh/2]\n\n    if (Math.abs(ac[0] - bc[0]) > (ar[0] + br[0])) return false\n    if (Math.abs(ac[1] - bc[1]) > (ar[1] + br[1])) return false\n\n    return true\n}\n\nvar pop = new Population(population, [\n    [[0, 0], [10, 900]],\n    [[890, 0], [900, 900]],\n    [[0, 0], [900, 10]],\n    [[0, 890], [900, 900]],\n    [[50, 50], [400, 200]],\n    [[750, 500], [900, 900]],\n    [[30, 600], [100, 750]],\n    [[700, 40], [750, 100]],\n    [[600, 300], [690, 310]],\n])\n\nvar lastTime = performance.now()\n\nfunction update() {\n    var curTime = performance.now()\n    var dt = (curTime - lastTime) / 1000\n    lastTime = curTime\n\n    ctx.clearRect(0, 0, canvas.width, canvas.height)\n\n    pop.update(dt)\n    pop.render(ctx)\n\n    requestAnimationFrame(update)\n}\n\nwindow.pop = pop\n\nupdate()\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9rBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACv+FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;"}